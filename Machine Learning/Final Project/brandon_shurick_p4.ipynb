{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Project \n",
    "======\n",
    "\n",
    "Kaggle Competition \n",
    "-----\n",
    "\n",
    "For this project I chose to do the active competition [San Francisco Crime Classification](https://www.kaggle.com/c/sf-crime/). I'll test out a number of different algorithms with test data. I am interested in this type of analysis as it is data science that contributes to the common good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Python functions\n",
    "from dateutil.relativedelta import *\n",
    "from datetime import datetime\n",
    "import re, math\n",
    "\n",
    "# Patsy \n",
    "from patsy import dmatrices\n",
    "\n",
    "# sklearn functions\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.preprocessing import OneHotEncoder, Imputer, Normalizer\n",
    "from sklearn.preprocessing import LabelEncoder, scale\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\\\n",
    "                        , f1_score, accuracy_score \n",
    "from sklearn.feature_selection import SelectKBest\\\n",
    "                        , SelectPercentile, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.decomposition import PCA\\\n",
    "                                , TruncatedSVD  #for sparse matrices\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.grid_search import GridSearchCV \n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Make plots BIG\n",
    "import matplotlib.pylab as pylab\n",
    "pylab.rcParams['figure.figsize'] = 12, 8\n",
    "\n",
    "# GIS functionality\n",
    "from mpl_toolkits.basemap import Basemap, cm\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import fiona\n",
    "import pysal \n",
    "from pyproj import Proj\n",
    "from pysal.cg.shapes import Point\n",
    "from pysal.cg.locators import PolygonLocator, PointLocator, BruteForcePointLocator \n",
    "from pysal.cg.sphere import arcdist\n",
    "\n",
    "# Multiprocessing \n",
    "import multiprocessing\n",
    "\n",
    "# Logging\n",
    "import logging\n",
    "FORMAT = '%(asctime)-15s %(message)s'\n",
    "logging.basicConfig(format=FORMAT)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MultiColumnLabelEncoder:\n",
    "    ''' Create a class that encodes\n",
    "        labels for a matrix of data\n",
    "    '''\n",
    "    def __init__(self, columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        out = dict()\n",
    "        if self.columns: out['columns'] = columns\n",
    "        return out\n",
    "\n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). \n",
    "        '''\n",
    "        numerics = [np.float16, np.float32, np.float64]\n",
    "        ints = [np.int16, np.int32, np.int64]\n",
    "        output = X.copy()\n",
    "        '''\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                if col.dtype not in numerics+ints:\n",
    "                    output[col] = LabelEncoder().fit_transform(output[col])\n",
    "                elif col.dtype not in ints:\n",
    "                    output[col] = scale(output[col])\n",
    "        else:\n",
    "        '''\n",
    "        try:\n",
    "            for colname,col in output.iteritems():\n",
    "                if col.dtype not in numerics+ints:\n",
    "                    # Turn text columns into ints\n",
    "                    output[colname] = LabelEncoder().fit_transform(output[colname])\n",
    "                elif col.dtype in numerics:\n",
    "                    # handle floats with scaling\n",
    "                    output[colname] = scale(output[colname])\n",
    "                elif col.dtype in ints:\n",
    "                    pass # leave integers alone\n",
    "        except:\n",
    "            output = LabelEncoder().fit_transform(output)\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878049, 9)\n"
     ]
    }
   ],
   "source": [
    "train_raw = pd.read_csv('Data/train.csv')\n",
    "test_raw = pd.read_csv('Data/test.csv')\n",
    "sample_submission = pd.read_csv('Data/sampleSubmission.csv')\n",
    "print train_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Submit first (bad) try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Dates</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Address</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-05-10 23:59:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>2000 Block of THOMAS AV</td>\n",
       "      <td>-122.399588</td>\n",
       "      <td>37.735051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-10 23:51:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>3RD ST / REVERE AV</td>\n",
       "      <td>-122.391523</td>\n",
       "      <td>37.732432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-05-10 23:50:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>NORTHERN</td>\n",
       "      <td>2000 Block of GOUGH ST</td>\n",
       "      <td>-122.426002</td>\n",
       "      <td>37.792212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-05-10 23:45:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>4700 Block of MISSION ST</td>\n",
       "      <td>-122.437394</td>\n",
       "      <td>37.721412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-05-10 23:45:00</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>4700 Block of MISSION ST</td>\n",
       "      <td>-122.437394</td>\n",
       "      <td>37.721412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                Dates DayOfWeek PdDistrict                   Address  \\\n",
       "0   0  2015-05-10 23:59:00    Sunday    BAYVIEW   2000 Block of THOMAS AV   \n",
       "1   1  2015-05-10 23:51:00    Sunday    BAYVIEW        3RD ST / REVERE AV   \n",
       "2   2  2015-05-10 23:50:00    Sunday   NORTHERN    2000 Block of GOUGH ST   \n",
       "3   3  2015-05-10 23:45:00    Sunday  INGLESIDE  4700 Block of MISSION ST   \n",
       "4   4  2015-05-10 23:45:00    Sunday  INGLESIDE  4700 Block of MISSION ST   \n",
       "\n",
       "            X          Y  \n",
       "0 -122.399588  37.735051  \n",
       "1 -122.391523  37.732432  \n",
       "2 -122.426002  37.792212  \n",
       "3 -122.437394  37.721412  \n",
       "4 -122.437394  37.721412  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ARSON</th>\n",
       "      <th>ASSAULT</th>\n",
       "      <th>BAD CHECKS</th>\n",
       "      <th>BRIBERY</th>\n",
       "      <th>BURGLARY</th>\n",
       "      <th>DISORDERLY CONDUCT</th>\n",
       "      <th>DRIVING UNDER THE INFLUENCE</th>\n",
       "      <th>DRUG/NARCOTIC</th>\n",
       "      <th>DRUNKENNESS</th>\n",
       "      <th>...</th>\n",
       "      <th>SEX OFFENSES NON FORCIBLE</th>\n",
       "      <th>STOLEN PROPERTY</th>\n",
       "      <th>SUICIDE</th>\n",
       "      <th>SUSPICIOUS OCC</th>\n",
       "      <th>TREA</th>\n",
       "      <th>TRESPASS</th>\n",
       "      <th>VANDALISM</th>\n",
       "      <th>VEHICLE THEFT</th>\n",
       "      <th>WARRANTS</th>\n",
       "      <th>WEAPON LAWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  ARSON  ASSAULT  BAD CHECKS  BRIBERY  BURGLARY  DISORDERLY CONDUCT  \\\n",
       "0   0      0        0           0        0         0                   0   \n",
       "1   1      0        0           0        0         0                   0   \n",
       "2   2      0        0           0        0         0                   0   \n",
       "3   3      0        0           0        0         0                   0   \n",
       "4   4      0        0           0        0         0                   0   \n",
       "\n",
       "   DRIVING UNDER THE INFLUENCE  DRUG/NARCOTIC  DRUNKENNESS     ...       \\\n",
       "0                            0              0            0     ...        \n",
       "1                            0              0            0     ...        \n",
       "2                            0              0            0     ...        \n",
       "3                            0              0            0     ...        \n",
       "4                            0              0            0     ...        \n",
       "\n",
       "   SEX OFFENSES NON FORCIBLE  STOLEN PROPERTY  SUICIDE  SUSPICIOUS OCC  TREA  \\\n",
       "0                          0                0        0               0     0   \n",
       "1                          0                0        0               0     0   \n",
       "2                          0                0        0               0     0   \n",
       "3                          0                0        0               0     0   \n",
       "4                          0                0        0               0     0   \n",
       "\n",
       "   TRESPASS  VANDALISM  VEHICLE THEFT  WARRANTS  WEAPON LAWS  \n",
       "0         0          0              0         1            0  \n",
       "1         0          0              0         1            0  \n",
       "2         0          0              0         1            0  \n",
       "3         0          0              0         1            0  \n",
       "4         0          0              0         1            0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data\\\n",
    ",train_labels = train_raw[['DayOfWeek'\\\n",
    "                                     ,'PdDistrict'\\\n",
    "                                     ,'Address'\\\n",
    "                                     ,'X'\\\n",
    "                                     ,'Y']][2001:]\\\n",
    "                            ,train_raw['Category'][2001:]\n",
    "dev_data\\\n",
    ",dev_labels = train_raw[['DayOfWeek'\\\n",
    "                                 ,'PdDistrict'\\\n",
    "                                 ,'Address'\\\n",
    "                                 ,'X'\\\n",
    "                                 ,'Y']][:1000]\\\n",
    "                            ,train_raw['Category'][:1000]\n",
    "dev_test_data\\\n",
    ",dev_test_labels = train_raw[['DayOfWeek'\\\n",
    "                                 ,'PdDistrict'\\\n",
    "                                 ,'Address'\\\n",
    "                                 ,'X'\\\n",
    "                                 ,'Y']][1001:2000]\\\n",
    "                            ,train_raw['Category'][1001:2000]\n",
    "test_data = test_raw[['DayOfWeek'\\\n",
    "                     ,'PdDistrict'\\\n",
    "                     ,'Address'\\\n",
    "                     ,'X'\\\n",
    "                     ,'Y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier() #leaving with default settings for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data needs to be preprocessed for RF in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recode(df):\n",
    "    numerics = ['float16', 'float32', 'float64']\n",
    "    ints = ['int16', 'int32', 'int64']\n",
    "    for i in range(df.shape[1]):\n",
    "        t = df.iloc[:,i].dtype\n",
    "        if t not in numerics or ints:\n",
    "            le = LabelEncoder()\n",
    "            le.fit(df.iloc[:,i])\n",
    "            df.iloc[:,i] = le.transform(df.iloc[:,i])\n",
    "        elif t not in ints:\n",
    "            df.iloc[:,i] = scale(df.iloc[:,i])\n",
    "    return df\n",
    "\n",
    "def recode_labels(df):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df)\n",
    "    return le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_data = recode(dev_data)\n",
    "dev_label_le = recode_labels(np.concatenate((dev_labels,dev_test_labels),axis=1))\n",
    "dev_labels = dev_label_le.transform(dev_labels)\n",
    "dev_test_data = recode(dev_test_data)\n",
    "dev_test_labels = dev_label_le.transform(dev_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(dev_data,dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = rf.predict(dev_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LARCENY/THEFT' 'LARCENY/THEFT' 'LARCENY/THEFT' 'VEHICLE THEFT'\n",
      " 'VEHICLE THEFT'] \n",
      "['OTHER OFFENSES' 'LARCENY/THEFT' 'LARCENY/THEFT' 'WARRANTS' 'WARRANTS']\n"
     ]
    }
   ],
   "source": [
    "actual_predictions = dev_label_le.inverse_transform(predictions)\n",
    "actual_labels = dev_label_le.inverse_transform(dev_test_labels)\n",
    "print actual_predictions[:5],'\\n',actual_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev Accuracy: 20.2%\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.sum((actual_predictions == actual_labels)*1.0)/len(dev_labels)\n",
    "print 'Dev Accuracy: {0}%'.format(accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train with real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/pandas/core/indexing.py:415: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = recode(train_data), recode(test_data)\n",
    "train_le = recode_labels(train_labels)\n",
    "train_labels = train_le.transform(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Make predictions and format for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = rf.predict(test_data)\n",
    "actual_predictions = train_le.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = len(test_data)\n",
    "submission = np.zeros((l,40),dtype=np.int32)\n",
    "submission[:,0] = range(l)\n",
    "cols = train_le.classes_ \n",
    "for i,c in enumerate(cols):\n",
    "    submission[:,i+1] = actual_predictions == c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ARSON</th>\n",
       "      <th>ASSAULT</th>\n",
       "      <th>BAD CHECKS</th>\n",
       "      <th>BRIBERY</th>\n",
       "      <th>BURGLARY</th>\n",
       "      <th>DISORDERLY CONDUCT</th>\n",
       "      <th>DRIVING UNDER THE INFLUENCE</th>\n",
       "      <th>DRUG/NARCOTIC</th>\n",
       "      <th>DRUNKENNESS</th>\n",
       "      <th>...</th>\n",
       "      <th>SEX OFFENSES NON FORCIBLE</th>\n",
       "      <th>STOLEN PROPERTY</th>\n",
       "      <th>SUICIDE</th>\n",
       "      <th>SUSPICIOUS OCC</th>\n",
       "      <th>TREA</th>\n",
       "      <th>TRESPASS</th>\n",
       "      <th>VANDALISM</th>\n",
       "      <th>VEHICLE THEFT</th>\n",
       "      <th>WARRANTS</th>\n",
       "      <th>WEAPON LAWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  ARSON  ASSAULT  BAD CHECKS  BRIBERY  BURGLARY  DISORDERLY CONDUCT  \\\n",
       "0   0      0        0           0        0         0                   0   \n",
       "1   1      0        0           0        0         0                   0   \n",
       "2   2      0        0           0        0         0                   0   \n",
       "3   3      0        1           0        0         0                   0   \n",
       "4   4      0        1           0        0         0                   0   \n",
       "\n",
       "   DRIVING UNDER THE INFLUENCE  DRUG/NARCOTIC  DRUNKENNESS     ...       \\\n",
       "0                            0              0            0     ...        \n",
       "1                            0              0            0     ...        \n",
       "2                            0              0            0     ...        \n",
       "3                            0              0            0     ...        \n",
       "4                            0              0            0     ...        \n",
       "\n",
       "   SEX OFFENSES NON FORCIBLE  STOLEN PROPERTY  SUICIDE  SUSPICIOUS OCC  TREA  \\\n",
       "0                          0                0        0               0     0   \n",
       "1                          0                0        0               0     0   \n",
       "2                          0                0        0               0     0   \n",
       "3                          0                0        0               0     0   \n",
       "4                          0                0        0               0     0   \n",
       "\n",
       "   TRESPASS  VANDALISM  VEHICLE THEFT  WARRANTS  WEAPON LAWS  \n",
       "0         0          0              0         0            0  \n",
       "1         0          0              1         0            0  \n",
       "2         0          0              0         0            0  \n",
       "3         0          0              0         0            0  \n",
       "4         0          0              0         0            0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_cols = ['Id']\n",
    "submission_cols.extend(cols)\n",
    "submission_df = pd.DataFrame(submission,columns=submission_cols)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save data to csv file for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv('Data/submission_file1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First attempt: Rank 208, score 26.95890, tested accuracy of ~20%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_test_data\\\n",
    ",dev_test_labels = train_raw[['DayOfWeek'\\\n",
    "                                 ,'PdDistrict'\\\n",
    "                                 ,'Address'\\\n",
    "                                 ,'X'\\\n",
    "                                 ,'Y']][1001:2000]\\\n",
    "                            ,train_raw['Category'][1001:2000]\n",
    "dev_test_data = recode(dev_test_data)\n",
    "predictions = rf.predict(dev_test_data)\n",
    "actual_predictions = train_le.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10c129ad0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdwAAAHaCAYAAACq+vjoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFFFJREFUeJzt3VGspGd93/Hff/esDXYsXGxkLMvFIMVtWiFhVUURtPKo\nopFz45AbIleRUBRFXKSAuKqJBD5qL5oggXxRwQ0mctuIKEoUChFpcSJGuKqSlMgGA6Y0ko1wZC9Q\ng8AYid2zTy92bJb12T3jM+/5z5zZz0c62jkzc5599t13zve875n3fWuMEQDgaJ1Y9wQA4EoguADQ\nQHABoIHgAkADwQWABjtHNXBVefszAFecMUbtd/+RbuGOMS77cd999x34HB8v/8NyffkfZ86cOfDj\nAx/4wIHPWfe/4zh+WF8t0+PyscxyvRy7lAGggeACQIO1Bnc2m63zr99aluvRuPPOO9c9ha1kfZ2e\nZXo0Vl2uddA+50t+YdVdSe5PcjLJx8cYv3fR4+OwY0O3s2fPTjLOzs6RvQ8ROAaqKmPKN01V1ckk\n/ynJXUn+SZJ7quoXDj9FANhuh92l/OYkfzfGeHKMcSbJHyb5lemmBQDb5bDBvSXJty74/KnFfQDA\nPg77C6elfjm7u7v74u3ZbOYX+QBslfl8nvl8vtRzD/Wmqar6xSS7Y4y7Fp+/P8m5C9845U1THCfe\nNAVMYfI3TSX5YpKfr6rbquqqJL+W5NOHnSAAbLtD/Tg+xjhbVf82yf/I+cOCHhhjPD7pzABgixz6\nONwDB7ZLmWPELmVgCkexSxkAeBkEFwAa2P+1pCl2j1ftu5eBDfDZz352knHuvvvuScbZBFPsZreL\nffvt7e2tPMbJkycnmMnms4ULAA0EFwAaCC4ANBBcAGgguADQQHABoIHgAkADwQWABoILAA0EFwAa\nCC4ANBBcAGgguADQQHABoIHgAkADwQWABjXFhdX3HbhqHNXYMLWp1tWqmmQc4Hiqqowx9v1GYAsX\nABoILgA0EFwAaCC4ANBAcAGggeACQAPBBYAGggsADQQXABoILgA0EFwAaCC4ANBAcAGggeACQAPB\nBYAGggsADQQXABrsrHsClzPGWHmMqppgJps1F6b3xBNPTDLOG97whknG2QR7e3srj3Hy5MkJZsIm\nO3fu3MpjTPW9cdO/x9rCBYAGggsADQQXABoILgA0EFwAaCC4ANBAcAGggeACQAPBBYAGggsADQQX\nABoILgA0EFwAaCC4ANBAcAGggeACQIOa4sLq+w5cNY5qbJjaFBfRTpITJ/wMC1eyqsoYo/Z7zHcH\nAGgguADQQHABoIHgAkADwQWABoILAA0EFwAaCC4ANBBcAGgguADQQHABoIHgAkADwQWABoILAA0E\nFwAaCC4ANNhZ9wRgE7gAPRzOGGPdU3hR1b7Xfd8YvjsAQAPBBYAGggsADQQXABoILgA0WOldylX1\nZJIfJNlLcmaM8eYpJgUA22bVw4JGktkY49kpJgMA22qKXcqbfeATAGyAVYM7kvxFVX2xqn5rigkB\nwDZadZfyW8cYT1fVa5I8VFVfH2M8/MKDu7u7Lz5xNptlNput+NcBwOaYz+eZz+dLPbemOi1XVd2X\n5LkxxocXn49NOuUXXM7Zs2cnGWdnx9lSubJs0vf5TTi1Y1VljLHvRA69S7mqrqmq6xa3r03yS0ke\nO+x4ALDNVvlx/KYkf7r4iWInyR+MMT43yawAYMtMtkv5JQPbpcwxYpcyHM4mfZ/f2l3KAMDyBBcA\nGtj/BUl+/OMfTzLOddddN8k4m+DMmTMrj3Hq1KkJZsIm24TduMeFLVwAaCC4ANBAcAGggeACQAPB\nBYAGggsADQQXABoILgA0EFwAaCC4ANBAcAGggeACQAPBBYAGggsADQQXABoILgA0EFwAaLCz7gnA\nJnjFK16x7ilsnFOnTq17CrBVbOECQAPBBYAGggsADQQXABoILgA0EFwAaCC4ANBAcAGggeACQAPB\nBYAGggsADQQXABoILgA0EFwAaCC4ANBAcAGggQvQL2mMsfIYVTXBTDgKP/jBDyYZ54YbbphknG0x\nxesm8drZZL43Ls8WLgA0EFwAaCC4ANBAcAGggeACQAPBBYAGggsADQQXABoILgA0EFwAaCC4ANBA\ncAGggeACQAPBBYAGggsADQQXABq4AP2SrpQLJF+prrvuunVPYSt53Ww//8fLs4ULAA0EFwAaCC4A\nNBBcAGgguADQQHABoIHgAkADwQWABoILAA0EFwAaCC4ANBBcAGgguADQQHABoIHgAkADwQWABjXG\nOJqBq8aqY589e3bleezs7Kw8RpLs7e2tPMbJkycnmAlHYaqLaB/V62kdvvOd76w8xg033DDBTKZx\n4oTti6Pw/e9/f+UxXvWqV00wk+lex6vOYYyx70SsgQDQQHABoIHgAkADwQWABgcGt6o+UVWnq+qx\nC+57dVU9VFXfqKrPVdX1RztNADjeltnC/f0kd110371JHhpj3J7kLxefAwCXcGBwxxgPJ/neRXff\nneTBxe0Hk7x94nkBwFY57O9wbxpjnF7cPp3kponmAwBbaeU3TS3ObrE9R/sDwBE47GmYTlfVa8cY\nz1TVzUm+vd+Tdnd3X7w9m80ym80O+dcBwOaZz+eZz+dLPXepUztW1W1JPjPGeOPi8w8l+X9jjN+r\nqnuTXD/GuPeir3Fqx4s4tePmcmrHl3JqR5bh1I4vncOhT+1YVZ9M8r+S/KOq+lZV/UaS303yr6vq\nG0n+1eJzAOASDtz8G2Pcc4mH3jbxXABga9nHAgANBBcAGgguADQQXABosNRhQYcaeILDgqDLuXPn\nJhnHoSdwZVvpsCAAYHWCCwANBBcAGgguADQQXABoILgA0EBwAaCB4AJAA8EFgAaCCwANBBcAGggu\nADQQXABoILgA0EBwAaCB4AJAg511TwA2wbPPPjvJODfeeOMk42yCMcbKY1Ttex1utoj1ZHm2cAGg\ngeACQAPBBYAGggsADQQXABoILgA0EFwAaCC4ANBAcAGggeACQAPBBYAGggsADQQXABoILgA0EFwA\naCC4ANBgoy9Av0kXNt7b21t5jJMnT04wE47CRz/60UnG+eAHPzjJOJvgJz/5ycpjXH311RPMZLO+\nF/Czpvi/mcqm/x/bwgWABoILAA0EFwAaCC4ANBBcAGgguADQQHABoIHgAkADwQWABoILAA0EFwAa\nCC4ANBBcAGgguADQQHABoIHgAkCDjb4A/SZdTPjECT+bbLNbbrll3VPYOJv0+mNz7e3trTzGzs5G\np2gyKgIADQQXABoILgA0EFwAaCC4ANBAcAGggeACQAPBBYAGggsADQQXABoILgA0EFwAaCC4ANBA\ncAGggeACQAPBBYAGNcY4moGrxlGNDQCbqKoyxqj9HrOFCwANBBcAGgguADQQXABocGBwq+oTVXW6\nqh674L7dqnqqqh5ZfNx1tNMEgONtmS3c309ycVBHko+MMe5YfPz36acGANvjwOCOMR5O8r19Htr3\nbc8AwEut8jvcd1fVl6rqgaq6frIZAcAWOmxwP5bk9UnelOTpJB+ebEYAsIV2DvNFY4xvv3C7qj6e\n5DP7PW93d/fF27PZLLPZ7DB/HQBspPl8nvl8vtRzlzq1Y1XdluQzY4w3Lj6/eYzx9OL2+5L88zHG\nv7noa5zaEYAryuVO7XjgFm5VfTLJnUlurKpvJbkvyayq3pTz71Z+Ism7JpwvAGwdFy8AgIm4eAEA\nrJngAkADwQWABoILAA0OdRzulWiKN4BVORvmpvrud787yTg33njjJOOsalPesDjVOu/1xzawhQsA\nDQQXABoILgA0EFwAaCC4ANBAcAGggeACQAPBBYAGggsADQQXABoILgA0EFwAaCC4ANBAcAGggeAC\nQAPBBYAGLkC/JBev3m7XXnvtuqcwqW1bX7ft37NNxhgrj3Gl/P/awgWABoILAA0EFwAaCC4ANBBc\nAGgguADQQHABoIHgAkADwQWABoILAA0EFwAaCC4ANBBcAGgguADQQHABoIHgAkADF6CHJGfOnJlk\nnFe+8pWTjLMJXFicZfg/Xp4tXABoILgA0EBwAaCB4AJAA8EFgAaCCwANBBcAGgguADQQXABoILgA\n0EBwAaCB4AJAA8EFgAaCCwANBBcAGgguADRwAXpIcu211657ChvHBehhWrZwAaCB4AJAA8EFgAaC\nCwANBBcAGgguADQQXABoILgA0EBwAaCB4AJAA8EFgAaCCwANBBcAGgguADQQXABoILgA0EBwAaDB\nzroncFyMMVYeo6ommAlH4amnnppknNe97nWTjLMJpljn2X6+Ny7PFi4ANBBcAGgguADQ4LLBrapb\nq+rzVfXVqvpKVb1ncf+rq+qhqvpGVX2uqq7vmS4AHE8HbeGeSfK+McY/TfKLSX67qn4hyb1JHhpj\n3J7kLxefAwCXcNngjjGeGWM8urj9XJLHk9yS5O4kDy6e9mCStx/lJAHguFv6d7hVdVuSO5L8dZKb\nxhinFw+dTnLT5DMDgC2y1HG4VfVzSf4kyXvHGD+88JipMcaoqn0PxNrd3X3x9mw2y2w2W2WuALBR\n5vN55vP5Us+tgw5arqpTSf4syZ+PMe5f3Pf1JLMxxjNVdXOSz48x/vFFXze26cB5B3dvt29+85uT\njLNNJ77Y29tbeYyTJ09OMBM2me+NP6uqMsbY9x900LuUK8kDSb72QmwXPp3knYvb70zyqSkmCgDb\n6qBdym9N8utJvlxVjyzue3+S303yR1X1m0meTPKOI5shAGyBywZ3jPE/c+mt4LdNPx0A2E7ONAUA\nDQQXABoILgA0EFwAaHDgcbiHHnjLjsNluz3//POTjHPNNddMMg5wPB36OFwAYBqCCwANBBcAGggu\nADQQXABoILgA0EBwAaCB4AJAA8EFgAaCCwANBBcAGgguADQQXABoILgA0EBwAaCB4AJAg511TwA2\nwaOPPjrJOG95y1smGWcTnDt3buUxTpzwM/22O3v27Mpj7OxcGSnyagCABoILAA0EFwAaCC4ANBBc\nAGgguADQQHABoIHgAkADwQWABoILAA0EFwAaCC4ANBBcAGgguADQQHABoIHgAkCDjb7q7xhj5TGq\naoKZbNZcmN6PfvSjdU9hUlOsr1NcWPyqq65aeQw2mwvQL88WLgA0EFwAaCC4ANBAcAGggeACQAPB\nBYAGggsADQQXABoILgA0EFwAaCC4ANBAcAGggeACQAPBBYAGggsADQQXABoILgA02Fn3BC6nqtY9\nBa4Qt99++7qnMKkpXjunTp2aYCZsu6uvvnrlMcYYE8xk85thCxcAGgguADQQXABoILgA0EBwAaCB\n4AJAA8EFgAaCCwANBBcAGgguADQQXABoILgA0EBwAaCB4AJAA8EFgAaCCwANNvoC9Jtk0y9szGpe\n85rXrHsKcCxNcfH4EyeujG2/K+NfCQBrJrgA0EBwAaDBZYNbVbdW1eer6qtV9ZWqes/i/t2qeqqq\nHll83NUzXQA4ng5609SZJO8bYzxaVT+X5G+r6qEkI8lHxhgfOfIZAsAWuGxwxxjPJHlmcfu5qno8\nyS2Lh71tFwCWtPTvcKvqtiR3JPmrxV3vrqovVdUDVXX9EcwNALbGUsfhLnYn/3GS9y62dD+W5N8v\nHv4PST6c5Dcv/rrd3d0Xb89ms8xmsxWnCwCbYz6fZz6fL/XcOuig5ao6leTPkvz5GOP+fR6/Lcln\nxhhvvOj+McUB0dDh+eefn2Sca665ZpJxNsEUr18njNl+586dW3mMbTrxRVVljLHvin/Qu5QryQNJ\nvnZhbKvq5gue9qtJHptiogCwrQ7apfzWJL+e5MtV9cjivt9Jck9VvSnn3638RJJ3Hd0UAeD4O3CX\n8qEHtkuZY8Qu5ZeyS5ll2KX8sw69S/moLfuLZl4ey/VofOELX1j3FLaS9XV6lunRWHW5Cu4WslyP\nxsMPP7zuKWwl6+v0LNOjcayDCwBXCsEFgAZH+qapIxkYADbYpd40dWTBBQB+yi5lAGgguADQQHAB\noMHagltVd1XV16vq/1bVv1vXPLZNVT1ZVV+uqkeq6m/WPZ/jqKo+UVWnq+qxC+57dVU9VFXfqKrP\nuSTly3eJ5bpbVU8t1tdHququdc7xOKqqW6vq81X11ar6SlW9Z3G/dXYFl1muh15n1/Kmqao6meT/\nJHlbkr9P8r+T3DPGeLx9Mlumqp5I8s/GGM+uey7HVVX9yyTPJfnPL1wFq6o+lOS7Y4wPLX5A/Adj\njHvXOc/j5hLL9b4kPxxjfGStkzvGquq1SV47xnh0cSnVv03y9iS/EevsoV1mub4jh1xn17WF++Yk\nfzfGeHKMcSbJHyb5lTXNZRs5ge0KxhgPJ/neRXffneTBxe0Hc/6Fx8twieWaWF9XMsZ4Zozx6OL2\nc0keT3JLrLMrucxyTQ65zq4ruLck+dYFnz+Vn/5DWM1I8hdV9cWq+q11T2aL3DTGOL24fTrJTeuc\nzJZ5d1V9qaoesNtzNYvrk9+R5K9jnZ3MBcv1rxZ3HWqdXVdwHfx7dN46xrgjyS8n+e3FbjwmtLgM\nlnV4Gh9L8vokb0rydJIPr3c6x9dit+efJHnvGOOHFz5mnT28xXL945xfrs9lhXV2XcH9+yS3XvD5\nrTm/lcuKxhhPL/78TpI/zfnd96zu9OJ3Oqmqm5N8e83z2QpjjG+PhSQfj/X1UKrqVM7H9r+MMT61\nuNs6u6ILlut/fWG5rrLOriu4X0zy81V1W1VdleTXknx6TXPZGlV1TVVdt7h9bZJfSvLY5b+KJX06\nyTsXt9+Z5FOXeS5LWoTgBb8a6+vLVucvOvxAkq+NMe6/4CHr7AoutVxXWWfXdmrHqvrlJPcnOZnk\ngTHGf1zLRLZIVb0+57dqk2QnyR9Yri9fVX0yyZ1Jbsz53319MMl/S/JHSf5hkieTvGOM8f11zfE4\n2me53pdklvO75kaSJ5K864LfO7KEqvoXSb6Q5Mv56W7j9yf5m1hnD+0Sy/V3ktyTQ66zzqUMAA2c\naQoAGgguADQQXABoILgA0EBwAaCB4AJAA8EFgAb/H+5QphCgasgzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1149acf90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf = confusion_matrix(dev_test_labels,actual_predictions)\n",
    "plt.imshow(conf, cmap='binary',interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>ASSAULT</th>\n",
       "      <th>BURGLARY</th>\n",
       "      <th>LARCENY/THEFT</th>\n",
       "      <th>NON-CRIMINAL</th>\n",
       "      <th>OTHER OFFENSES</th>\n",
       "      <th>RECOVERED VEHICLE</th>\n",
       "      <th>ROBBERY</th>\n",
       "      <th>VANDALISM</th>\n",
       "      <th>VEHICLE THEFT</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ARSON</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASSAULT</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRIBERY</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BURGLARY</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DISORDERLY CONDUCT</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRIVING UNDER THE INFLUENCE</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRUG/NARCOTIC</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRUNKENNESS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRAUD</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KIDNAPPING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LARCENY/THEFT</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIQUOR LAWS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISSING PERSON</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NON-CRIMINAL</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTHER OFFENSES</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROBBERY</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SECONDARY CODES</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEX OFFENSES FORCIBLE</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STOLEN PROPERTY</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUSPICIOUS OCC</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRESPASS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VANDALISM</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VEHICLE THEFT</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WARRANTS</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WEAPON LAWS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>852</td>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "      <td>6</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted                    ASSAULT  BURGLARY  LARCENY/THEFT  NON-CRIMINAL  \\\n",
       "True                                                                          \n",
       "ARSON                              0         0              4             0   \n",
       "ASSAULT                            0         1             71             0   \n",
       "BRIBERY                            0         0              1             0   \n",
       "BURGLARY                           1         1             31             0   \n",
       "DISORDERLY CONDUCT                 0         0              2             0   \n",
       "DRIVING UNDER THE INFLUENCE        0         0              4             0   \n",
       "DRUG/NARCOTIC                      0         0             12             0   \n",
       "DRUNKENNESS                        0         0              5             0   \n",
       "FRAUD                              0         1             18             0   \n",
       "KIDNAPPING                         0         0              6             0   \n",
       "LARCENY/THEFT                      4         3            233             0   \n",
       "LIQUOR LAWS                        0         0              2             0   \n",
       "MISSING PERSON                     0         0             19             0   \n",
       "NON-CRIMINAL                       1         3            115             0   \n",
       "OTHER OFFENSES                     0         1             91             0   \n",
       "ROBBERY                            0         1             19             1   \n",
       "SECONDARY CODES                    0         0              9             0   \n",
       "SEX OFFENSES FORCIBLE              0         0             13             0   \n",
       "STOLEN PROPERTY                    0         0              3             0   \n",
       "SUSPICIOUS OCC                     0         1             29             0   \n",
       "TRESPASS                           0         0             10             0   \n",
       "VANDALISM                          0         0             53             0   \n",
       "VEHICLE THEFT                      1         1             63             1   \n",
       "WARRANTS                           0         1             29             0   \n",
       "WEAPON LAWS                        0         0             10             0   \n",
       "All                                7        14            852             2   \n",
       "\n",
       "Predicted                    OTHER OFFENSES  RECOVERED VEHICLE  ROBBERY  \\\n",
       "True                                                                      \n",
       "ARSON                                     0                  0        0   \n",
       "ASSAULT                                   4                  0        0   \n",
       "BRIBERY                                   0                  0        0   \n",
       "BURGLARY                                  3                  0        0   \n",
       "DISORDERLY CONDUCT                        0                  0        0   \n",
       "DRIVING UNDER THE INFLUENCE               0                  0        0   \n",
       "DRUG/NARCOTIC                             5                  0        0   \n",
       "DRUNKENNESS                               0                  0        0   \n",
       "FRAUD                                     0                  1        0   \n",
       "KIDNAPPING                                0                  0        0   \n",
       "LARCENY/THEFT                            20                  2        2   \n",
       "LIQUOR LAWS                               0                  0        0   \n",
       "MISSING PERSON                            1                  0        0   \n",
       "NON-CRIMINAL                              7                  0        1   \n",
       "OTHER OFFENSES                            6                  0        1   \n",
       "ROBBERY                                   1                  0        1   \n",
       "SECONDARY CODES                           0                  0        0   \n",
       "SEX OFFENSES FORCIBLE                     1                  0        0   \n",
       "STOLEN PROPERTY                           2                  0        0   \n",
       "SUSPICIOUS OCC                            3                  0        0   \n",
       "TRESPASS                                  0                  0        0   \n",
       "VANDALISM                                 2                  0        0   \n",
       "VEHICLE THEFT                             6                  0        0   \n",
       "WARRANTS                                  1                  0        0   \n",
       "WEAPON LAWS                               1                  0        0   \n",
       "All                                      63                  3        5   \n",
       "\n",
       "Predicted                    VANDALISM  VEHICLE THEFT  All  \n",
       "True                                                        \n",
       "ARSON                                0              0    4  \n",
       "ASSAULT                              3              0   79  \n",
       "BRIBERY                              0              0    1  \n",
       "BURGLARY                             2              1   39  \n",
       "DISORDERLY CONDUCT                   0              0    2  \n",
       "DRIVING UNDER THE INFLUENCE          1              1    6  \n",
       "DRUG/NARCOTIC                        0              0   17  \n",
       "DRUNKENNESS                          0              0    5  \n",
       "FRAUD                                1              0   21  \n",
       "KIDNAPPING                           0              0    6  \n",
       "LARCENY/THEFT                       15              1  280  \n",
       "LIQUOR LAWS                          0              0    2  \n",
       "MISSING PERSON                       1              0   21  \n",
       "NON-CRIMINAL                         2              1  130  \n",
       "OTHER OFFENSES                       5              1  105  \n",
       "ROBBERY                              0              0   23  \n",
       "SECONDARY CODES                      1              0   10  \n",
       "SEX OFFENSES FORCIBLE                0              0   14  \n",
       "STOLEN PROPERTY                      0              0    5  \n",
       "SUSPICIOUS OCC                       1              0   34  \n",
       "TRESPASS                             0              0   10  \n",
       "VANDALISM                            4              0   59  \n",
       "VEHICLE THEFT                        8              0   80  \n",
       "WARRANTS                             1              1   33  \n",
       "WEAPON LAWS                          2              0   13  \n",
       "All                                 47              6  999  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(dev_test_labels, actual_predictions, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since samples are not weighted well in terms of categories, the model seems to be having difficulties with categories that have a larger amount of observations - likely because all of the conditions used to predict crimes are seen more frequently for the samples with more observations. For example, there is no predictions that are Liqour Law because this is an infrequent category in the training data. To make the model generalize better it will be necessary to resample the dataset so that possible outcomes are represented more evenly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Tests to increase accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Load of data started\n",
      "INFO:root:Load of data finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(878049, 9)\n"
     ]
    }
   ],
   "source": [
    "logger.info('Load of data started')\n",
    "train_raw = pd.read_csv('Data/train.csv')\n",
    "test_raw = pd.read_csv('Data/test.csv')\n",
    "sample_submission = pd.read_csv('Data/sampleSubmission.csv')\n",
    "logger.info('Load of data finished')\n",
    "print train_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Deep dive into crimes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\n",
      "ARSON                            1513\n",
      "ASSAULT                         76876\n",
      "BAD CHECKS                        406\n",
      "BRIBERY                           289\n",
      "BURGLARY                        36755\n",
      "DISORDERLY CONDUCT               4320\n",
      "DRIVING UNDER THE INFLUENCE      2268\n",
      "DRUG/NARCOTIC                   53971\n",
      "DRUNKENNESS                      4280\n",
      "EMBEZZLEMENT                     1166\n",
      "EXTORTION                         256\n",
      "FAMILY OFFENSES                   491\n",
      "FORGERY/COUNTERFEITING          10609\n",
      "FRAUD                           16679\n",
      "GAMBLING                          146\n",
      "KIDNAPPING                       2341\n",
      "LARCENY/THEFT                  174900\n",
      "LIQUOR LAWS                      1903\n",
      "LOITERING                        1225\n",
      "MISSING PERSON                  25989\n",
      "NON-CRIMINAL                    92304\n",
      "OTHER OFFENSES                 126182\n",
      "PORNOGRAPHY/OBSCENE MAT            22\n",
      "PROSTITUTION                     7484\n",
      "RECOVERED VEHICLE                3138\n",
      "ROBBERY                         23000\n",
      "RUNAWAY                          1946\n",
      "SECONDARY CODES                  9985\n",
      "SEX OFFENSES FORCIBLE            4388\n",
      "SEX OFFENSES NON FORCIBLE         148\n",
      "STOLEN PROPERTY                  4540\n",
      "SUICIDE                           508\n",
      "SUSPICIOUS OCC                  31414\n",
      "TREA                                6\n",
      "TRESPASS                         7326\n",
      "VANDALISM                       44725\n",
      "VEHICLE THEFT                   53781\n",
      "WARRANTS                        42214\n",
      "WEAPON LAWS                      8555\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print train_raw.groupby(['Category']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('SUSPICIOUS OCC', 'SUSPICIOUS OCCURRENCE'), 21891)\n",
      "(('SUSPICIOUS OCC', 'INVESTIGATIVE DETENTION'), 5822)\n",
      "(('SUSPICIOUS OCC', 'SUSPICIOUS PERSON'), 1943)\n",
      "(('SUSPICIOUS OCC', 'SUSPICIOUS ACT TOWARDS FEMALE'), 757)\n",
      "(('SUSPICIOUS OCC', 'SUSPICIOUS OCCURRENCE, POSSIBLE SHOTS FIRED'), 389)\n",
      "(('SUSPICIOUS OCC', 'SUSPICIOUS ACT TOWARDS CHILD'), 273)\n",
      "(('SUSPICIOUS OCC', 'UNUSUAL OCCURENCE'), 173)\n",
      "(('SUSPICIOUS OCC', 'SUSPICIOUS AUTO, POSSIBLY SEX'), 166)\n"
     ]
    }
   ],
   "source": [
    "def show_descripts(cat,first_n=10):\n",
    "    ''' A function to evaluate descriptions for a category \n",
    "        sorted by the number of crimes\n",
    "    '''\n",
    "    g = train_raw[train_raw['Category']==cat]\\\n",
    "        [['Category','Descript']]\\\n",
    "        .groupby(['Category','Descript']).agg(len)\n",
    "    for x in sorted(zip(g.index,g.values),key=lambda x: x[1], reverse=True)[:first_n]:\n",
    "        print x\n",
    "\n",
    "show_descripts('SUSPICIOUS OCC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've noticed that categories aren't the best at describing the data in terms a model would understand. Some categories have a lot of crimes included that would make it difficult to have an accurate model, no matter what supplemental data sources are attached to the training set. Below I am looking to create a smaller number of 'meta-categories' that will be easier to predict by grouping individual categories and by including individual descriptions into appropriate meta-categories that will be easier for a model to interpret. \n",
    "\n",
    "After re-classifying the crimes for the training set, I will attempt to build a prediction model that will be used to predict meta-categories for the test set - which will then be utilized as an additional feature in the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Creation of collar_id started\n",
      "INFO:root:Creation of collar_id ended\n"
     ]
    }
   ],
   "source": [
    "def collar_crimes(x,y):\n",
    "    ''' Add a meta category for \n",
    "        crimes based on the skills\n",
    "        required\n",
    "    '''\n",
    "    blue_collar_violent = [ \n",
    "                   \"ASSAULT\"\n",
    "                   , \"KIDNAPPING\"\n",
    "                   , \"ARSON\"\n",
    "                   , 'DOMESTIC VIOLENCE'\n",
    "                   , 'GANG ACTIVITY'\n",
    "                  ]\n",
    "    blue_collar_other = [\n",
    "                \"VANDALISM\"\n",
    "                ,\"DISORDERLY CONDUCT\"\n",
    "                ,\"TRESPASS\"\n",
    "                ,'TREA'\n",
    "               , 'LOITERING'\n",
    "                ,'RESISTING ARREST'\n",
    "                ,'PROBATION VIOLATION'\n",
    "                ,'PROBATION VIOLATION'\n",
    "                ,'VIOLATION OF RESTRAINING ORDER'\n",
    "                ,'PAROLE VIOLATION'\n",
    "    ]\n",
    "    sex_crimes = [\n",
    "            'SEX OFFENSES FORCIBLE',\n",
    "            'PORNOGRAPHY/OBSCENE MAT',\n",
    "            'SEX OFFENSES NON FORCIBLE',\n",
    "            'PROSTITUTION'\n",
    "        ]\n",
    "    alcohol = [\n",
    "        'DRIVING UNDER THE INFLUENCE',\n",
    "        'DRUNKENNESS',\n",
    "        'LIQUOR LAWS'\n",
    "    ]\n",
    "    drug = ['DRUG/NARCOTIC']\n",
    "    theft = [\n",
    "        'LARCENY/THEFT',\n",
    "         'STOLEN PROPERTY',\n",
    "         \"ROBBERY\",\n",
    "         'CREDIT CARD, THEFT BY USE OF',\n",
    "        'FRAUDULENT USE OF AUTOMATED TELLER CARD',\n",
    "        'BURGLARY'\n",
    "    ]\n",
    "    vehicle = [\n",
    "        'RECOVERED VEHICLE',\n",
    "        'VEHICLE THEFT',\n",
    "        'DRIVERS LICENSE, SUSPENDED OR REVOKED',\n",
    "        'TRAFFIC VIOLATION',\n",
    "        'TRAFFIC VIOLATION ARREST',\n",
    "        'DRIVERS LICENSE, SUSPENDED OR REVOKED',\n",
    "        'LOST/STOLEN LICENSE PLATE',\n",
    "        'IMPOUNDED VEHICLE',\n",
    "        'TRAFFIC ACCIDENT',\n",
    "        'MALICIOUS MISCHIEF, VANDALISM OF VEHICLES'\n",
    "    ]\n",
    "    noncrime = [\n",
    "        'MISSING PERSON',\n",
    "        'RUNAWAY',\n",
    "        'SUICIDE',\n",
    "        'NON-CRIMINAL',\n",
    "        'SUSPICIOUS OCC'\n",
    "    ]\n",
    "    white_collar = [ \n",
    "        \"FRAUD\"\n",
    "       , \"FORGERY/COUNTERFEITING\"\n",
    "       , \"BAD CHECKS\" \n",
    "       , \"EXTORTION\"\n",
    "       , \"EMBEZZLEMENT\"\n",
    "       , \"BRIBERY\"\n",
    "        , 'CONSPIRACY'\n",
    "    ]\n",
    "    if x in blue_collar_violent or y in blue_collar_violent: return 1\n",
    "    elif x in sex_crimes or y in sex_crimes: return 2\n",
    "    elif x in alcohol or y in alcohol: return 3\n",
    "    elif x in drug or y in drug: return 4\n",
    "    elif x in theft or y in theft: return 5\n",
    "    elif x in vehicle or y in vehicle: return 6\n",
    "    elif x in noncrime or y in noncrime: return 7\n",
    "    elif x in white_collar or y in white_collar: return 8\n",
    "    elif x in blue_collar_other or y in blue_collar_other: return 9\n",
    "    else: return 10\n",
    "collar_crimes = np.vectorize(collar_crimes,otypes=[np.int64])\n",
    "logger.info('Creation of collar_id started')\n",
    "train_raw['collar_id'] = collar_crimes(train_raw['Category'],train_raw['Descript'])\n",
    "logger.info('Creation of collar_id ended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('ASSAULT', 'BATTERY'), 27441)\n",
      "(('ASSAULT', 'THREATS AGAINST LIFE'), 14716)\n",
      "(('SECONDARY CODES', 'DOMESTIC VIOLENCE'), 7449)\n",
      "(('ASSAULT', 'INFLICT INJURY ON COHABITEE'), 7122)\n",
      "(('ASSAULT', 'AGGRAVATED ASSAULT WITH A DEADLY WEAPON'), 6451)\n",
      "(('ASSAULT', 'AGGRAVATED ASSAULT WITH BODILY FORCE'), 4898)\n",
      "(('ASSAULT', 'BATTERY, FORMER SPOUSE OR DATING RELATIONSHIP'), 2712)\n",
      "(('ASSAULT', 'AGGRAVATED ASSAULT WITH A KNIFE'), 2442)\n",
      "(('KIDNAPPING', 'FALSE IMPRISONMENT'), 1410)\n",
      "(('ASSAULT', 'BATTERY OF A POLICE OFFICER'), 1331)\n"
     ]
    }
   ],
   "source": [
    "def show_newcategories(col,first_n=10):\n",
    "    ''' Evaluate how crimes are fit into the new \n",
    "        categories defined above\n",
    "    '''\n",
    "    g = train_raw[train_raw['collar_id']==col]\\\n",
    "        [['Category','Descript']]\\\n",
    "        .groupby(['Category','Descript']).agg(len)\n",
    "    for x in sorted(zip(g.index,g.values),key=lambda x: x[1], reverse=True)[:first_n]:\n",
    "        print x\n",
    "\n",
    "show_newcategories(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing I've noticed is how some categories have minimal amounts of crimes which makes it difficult to build a model because there is such a strong bias in predicting crimes that occur the most often. I am creating a sampling methodology that samples with replacement in order to gather a more even amount of observations in each dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Category   Value\n",
      "0                         ARSON    1513\n",
      "1                       ASSAULT   76876\n",
      "2                    BAD CHECKS     406\n",
      "3                       BRIBERY     289\n",
      "4                      BURGLARY   36755\n",
      "5            DISORDERLY CONDUCT    4320\n",
      "6   DRIVING UNDER THE INFLUENCE    2268\n",
      "7                 DRUG/NARCOTIC   53971\n",
      "8                   DRUNKENNESS    4280\n",
      "9                  EMBEZZLEMENT    1166\n",
      "10                    EXTORTION     256\n",
      "11              FAMILY OFFENSES     491\n",
      "12       FORGERY/COUNTERFEITING   10609\n",
      "13                        FRAUD   16679\n",
      "14                     GAMBLING     146\n",
      "15                   KIDNAPPING    2341\n",
      "16                LARCENY/THEFT  174900\n",
      "17                  LIQUOR LAWS    1903\n",
      "18                    LOITERING    1225\n",
      "19               MISSING PERSON   25989\n",
      "20                 NON-CRIMINAL   92304\n",
      "21               OTHER OFFENSES  126182\n",
      "22      PORNOGRAPHY/OBSCENE MAT      22\n",
      "23                 PROSTITUTION    7484\n",
      "24            RECOVERED VEHICLE    3138\n",
      "25                      ROBBERY   23000\n",
      "26                      RUNAWAY    1946\n",
      "27              SECONDARY CODES    9985\n",
      "28        SEX OFFENSES FORCIBLE    4388\n",
      "29    SEX OFFENSES NON FORCIBLE     148\n",
      "30              STOLEN PROPERTY    4540\n",
      "31                      SUICIDE     508\n",
      "32               SUSPICIOUS OCC   31414\n",
      "33                         TREA       6\n",
      "34                     TRESPASS    7326\n",
      "35                    VANDALISM   44725\n",
      "36                VEHICLE THEFT   53781\n",
      "37                     WARRANTS   42214\n",
      "38                  WEAPON LAWS    8555\n"
     ]
    }
   ],
   "source": [
    "# Gather counts of each category \n",
    "g = train_raw[['Category','Descript']].groupby(['Category']).agg(len)\n",
    "group_cnts = pd.DataFrame({'Category':np.array(g.index).T,'Value':np.array(g.T)[0]})\n",
    "print group_cnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_df(df,group_name,groups,group_n,\\\n",
    "              group_cnts,nX=10):\n",
    "    ''' Do sampling manually with \n",
    "        even group size \n",
    "        \n",
    "        Keeps nX times as many observations\n",
    "        as the original counts, or as many \n",
    "        new samples with replacement until\n",
    "        group_n is reached (whichever is \n",
    "        the lower amount).\n",
    "    '''\n",
    "    x = df.copy()\n",
    "    out = []\n",
    "    for g in groups:\n",
    "        try:\n",
    "            # Replace only when necessary\n",
    "            out.append(x[x[group_name]==g].\\\n",
    "                   sample(group_n,replace=False))\n",
    "        except:\n",
    "            i = len(x[x[group_name]==g])\n",
    "            n = group_cnts[group_cnts.iloc[:,0]\\\n",
    "                           ==g].iloc[0,1]\n",
    "            out.append(x[x[group_name]==g])\n",
    "            out.append(x[x[group_name]==g]\\\n",
    "                   .sample(min([group_n-i,n*(nX-1)])\\\n",
    "                           ,replace=True))\n",
    "    out_df = pd.concat(out)\n",
    "    s = out_df.sample(group_n*len(groups)\\\n",
    "                      ,replace=True)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add time of day \n",
    "\n",
    "Since a timestamp is not good for the generalization of the model, attempt bucketing of hours within each day, and break off day of month and year of crime and separate dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Datetime conversion started\n",
      "INFO:root:DaySegment creation started\n",
      "INFO:root:TimeOfDay creation started\n",
      "INFO:root:DayOfMonth creation started\n",
      "INFO:root:Year creation started\n",
      "INFO:root:Month creation started\n",
      "INFO:root:YearQtr creation started\n",
      "INFO:root:YearSegment creation started\n",
      "INFO:root:Date feature processing ended\n"
     ]
    }
   ],
   "source": [
    "ceil = np.vectorize(math.ceil)\n",
    "    \n",
    "logger.info('Datetime conversion started')\n",
    "train_raw['Dates'] = pd.to_datetime(train_raw['Dates'])\n",
    "test_raw['Dates'] = pd.to_datetime(test_raw['Dates'])\n",
    "\n",
    "logger.info('DaySegment creation started')\n",
    "train_raw['DaySegment'] = ceil((train_raw['Dates'].dt.hour+1)/4).astype(np.int)\n",
    "test_raw['DaySegment'] = ceil((test_raw['Dates'].dt.hour+1)/4).astype(np.int)\n",
    "\n",
    "logger.info('TimeOfDay creation started')\n",
    "train_raw['TimeOfDay'] = train_raw['Dates'].dt.hour\n",
    "test_raw['TimeOfDay'] = test_raw['Dates'].dt.hour\n",
    "\n",
    "logger.info('DayOfMonth creation started')\n",
    "train_raw['DayOfMonth'] = train_raw['Dates'].dt.day\n",
    "test_raw['DayOfMonth'] = test_raw['Dates'].dt.day\n",
    "\n",
    "logger.info('Year creation started')\n",
    "train_raw['Year'] = train_raw['Dates'].dt.year\n",
    "test_raw['Year'] = test_raw['Dates'].dt.year\n",
    "\n",
    "logger.info('Month creation started')\n",
    "train_raw['Month'] = train_raw['Dates'].dt.month\n",
    "test_raw['Month'] = test_raw['Dates'].dt.month\n",
    "\n",
    "logger.info('YearQtr creation started')\n",
    "train_raw['YearQtr'] = train_raw['Dates'].dt.year*100\\\n",
    "    +ceil(train_raw['Dates'].dt.month/4).astype(np.int)\n",
    "test_raw['YearQtr'] = test_raw['Dates'].dt.year*100\\\n",
    "    +ceil(test_raw['Dates'].dt.month/4).astype(np.int)\n",
    "\n",
    "logger.info('YearSegment creation started')\n",
    "train_raw['YearSegment'] = ceil(train_raw['Dates'].dt.month/4).astype(np.int)\n",
    "test_raw['YearSegment'] =  ceil(test_raw['Dates'].dt.month/4).astype(np.int)\n",
    "logger.info('Date feature processing ended')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add clustering based on lat/lon and time of day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, by using the exact location of the crime, the model does not generalize very well. I KMeans to segment training data into clusters based on location, time of day, and year and add both the cluster label and distance from centroid as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_clusters(range_n_clusters,fields=['X','Y','YearSegment','Year']):\n",
    "    km_models = []\n",
    "    i_scores = []\n",
    "    tr = train_raw[fields].copy()\n",
    "    tr = le.fit_transform(tr)\n",
    "    for n_clusters in range(range_n_clusters):\n",
    "        logger.info('Cluster {} started'.format(n_clusters))\n",
    "        if n_clusters>1:\n",
    "            km = KMeans(n_clusters=n_clusters, random_state=5)\n",
    "            km.fit(tr)\n",
    "            km_models.append(km)\n",
    "            inertia = km.inertia_ \n",
    "            print 'For {0}, inertia = {1}'.format(\n",
    "                n_clusters, inertia\n",
    "            )\n",
    "            i_scores.append(inertia)\n",
    "       \n",
    "    # plot results\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title('KMeans inertia values')\n",
    "    ax.set_xlabel('Clusters')\n",
    "    ax.set_ylabel('Inertia')\n",
    "    ax.plot([i for i in range(range_n_clusters) \\\n",
    "             if i>1],i_scores,'-', linewidth=2)\n",
    "    plt.show()\n",
    "    \n",
    "#test_clusters(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the clustering process, I found that there are a few points with what must be default values of lat/lon coordinates: 90,-120.5. Those are values that aren't interpretable by GIS packages and cause significant issues with clustering as well, so I have to manually impute them with better default values here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Manually impute bad X,Y values as \n",
    "train_raw.loc[train_raw['X']==-120.5,['X']] = np.mean(train_raw['X'])\n",
    "train_raw.loc[train_raw['Y']==90,['Y']] = np.mean(train_raw['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Clustering started\n",
      "INFO:root:Clustering training data\n"
     ]
    }
   ],
   "source": [
    "# Reload data in case of changes\n",
    "logger.info('Clustering started')\n",
    "le = MultiColumnLabelEncoder()\n",
    "nrm = Normalizer()\n",
    "tr = train_raw[['X','Y','TimeOfDay','YearQtr']].copy()\n",
    "pl = Pipeline([('le',le),('nrm',nrm)])\n",
    "tr = pl.fit_transform(tr)\n",
    "\n",
    "# Set k\n",
    "k = 20\n",
    "\n",
    "# Initialize Kmeans model\n",
    "km = KMeans(n_clusters=k)\n",
    "logger.info('Clustering training data')\n",
    "train_raw['KMcluster'] = km.fit_predict(tr)\n",
    "\n",
    "# Calculate distances\n",
    "logger.info('Clustering distance calculation for training data')\n",
    "distances = km.transform(tr)\n",
    "train_raw['KMdistance'] = np.min(distances,axis=1)\n",
    "\n",
    "# Predict for test dataset\n",
    "logger.info('Clustering training data')\n",
    "tr = test_raw[['X','Y','TimeOfDay','YearQtr']].copy()\n",
    "tr = le.transform(tr)\n",
    "test_raw['KMcluster'] = km.predict(tr)\n",
    "logger.info('Clustering distance calculation for training data')\n",
    "distances = km.transform(tr)\n",
    "test_raw['KMdistance'] = np.min(distances,axis=1)\n",
    "logger.info('Clustering finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_clustercat(cluster):\n",
    "    ''' A function that shows top crimes in each cluster '''\n",
    "    g = train_raw[train_raw['KMcluster']==cluster].\\\n",
    "        groupby(['Category','KMcluster'])['Category'].agg(len)\n",
    "    for x in sorted(zip(g.index,g.values),key=lambda x: \\\n",
    "                    (x[0][1],x[1]), reverse=True)[:10]:\n",
    "        print x\n",
    "    \n",
    "show_clustercat(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_clusters():\n",
    "    ''' Show all clusters in individual scatterplots '''\n",
    "    f, axarr = plt.subplots(4, 5, sharex=True, sharey=True)\n",
    "    le = MultiColumnLabelEncoder()\n",
    "    nrm = Normalizer()\n",
    "    imp = Imputer()\n",
    "    tr = train_raw[['X','Y','TimeOfDay','YearQtr']].copy()\n",
    "    pl = Pipeline([('le',le),('imp',imp),('nrm',nrm)])\n",
    "    tr = pl.fit_transform(tr)\n",
    "    pca = PCA(n_components=2)\n",
    "    X = pca.fit_transform(tr)\n",
    "    K = np.array(train_raw['KMcluster'])\n",
    "    for i in range(20):\n",
    "        if i<5: e=0\n",
    "        elif i<10: e=1\n",
    "        elif i<15: e=2\n",
    "        else: e=3\n",
    "        z = i - 5*e\n",
    "        axarr[e, z].plot(X[K==i,0]\\\n",
    "                            ,X[K==i,1]\\\n",
    "                            ,'bo')\n",
    "        axarr[e, z].set_title('K:{}'.format(i))\n",
    "        plt.setp([a.get_xticklabels() for a in axarr[0, :]], visible=False)\n",
    "        plt.setp([a.get_yticklabels() for a in axarr[:, 1]], visible=False)\n",
    "\n",
    "plot_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform_address(x):\n",
    "    x = re.sub(r'[0-9\\/]','',x)\n",
    "    x = x.upper()\n",
    "    x = x.split()\n",
    "    x = sorted(set(x))\n",
    "    #removes = ['OF',' ','AV','ST','BL','CT','WY'\\\n",
    "    #           ,'DR','PL','RD','LN','TR','CR','TH'\\\n",
    "    #           ,'THE','BLOCK','HY','BLVD']\n",
    "    removes = ['OF','THE','TH',' ']\n",
    "    x = [ z for z in x if z not in removes ]\n",
    "    x = ' '.join(x)\n",
    "    x = re.sub(r'\\ \\ ',' ',x)\n",
    "    x = re.sub(r'^\\ ','',x)\n",
    "    return x\n",
    "\n",
    "transform_address = np.vectorize(transform_address)\n",
    "train_raw['AddressMod'] = transform_address(train_raw['Address'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Get data from other sources\n",
    "\n",
    "SF OpenData has a ton of supplemental data sources that will be great to try out for this effort.  \n",
    "\n",
    "NOTE: one of them is actually a list of crimes that seems to match data in the training set. I will NOT use that data to train my model or match against the test dataset; however, I believe that many contestants are doing this, given that there is a very clear separation in scores that indicates to me that maybe there is some cheating happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://spatialreference.org/ref/epsg/2227/\n",
    "p = Proj('+proj=lcc +init=EPSG:2227 +datum=NAD83 +units=us-ft +no_defs',preserve_units=True)\n",
    "convert_vals = np.vectorize(lambda x,y: p(x,y))\n",
    "convert_vals_inv = np.vectorize(lambda x,y: p(x,y,inverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shpfilename_elect = 'Data/SanFranciscoElectricityUse/SanFranciscoElectricityUse.shp'\n",
    "shpfilename_school = 'Data/schools_public_pt/schools_public_pt.shp'\n",
    "shpfilename_zoning = 'Data/Zoning/Zoning_Districts.shp'\n",
    "shpfilename_neighborhoods = 'Data/planning_neighborhoods/planning_neighborhoods.shp'\n",
    "shpfilename_jobdensity = 'Data/SanFranciscoJobDensity/SanFranciscoJobDensity.shp'\n",
    "street_tree_locations = 'Data/Street_Tree_List.csv'\n",
    "report311_locations = 'Data/All_cases_map_view.csv'\n",
    "business_locations = 'Data/Registered_Business_Map.csv'\n",
    "park_locations = 'Data/Park_and_Open_Space_Map.csv'\n",
    "offstreet_parking_locations = 'Data/Off-street_parking_lots_and_parking_garages_map.csv'\n",
    "private_garage_locations = 'Data/PrivateGarages_Lots.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert lat/lon to coordinates that match shape files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_raw['New_X'], train_raw['New_Y'] = \\\n",
    "    convert_vals(train_raw['X'],train_raw['Y'])\n",
    "test_raw['New_X'], test_raw['New_Y'] = \\\n",
    "    convert_vals(test_raw['X'],test_raw['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_points = [ Point((x,y)) for x,y in zip(train_raw['New_X'],train_raw['New_Y']) ]\n",
    "test_points = [ Point((x,y)) for x,y in zip(train_raw['New_X'],train_raw['New_Y']) ]\n",
    "points = base_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read and process CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trees = pd.read_csv(street_tree_locations)\n",
    "report311 = pd.read_csv(report311_locations)\n",
    "businesses = pd.read_csv(business_locations)\n",
    "parks = pd.read_csv(park_locations, quotechar = \"\\\"\")\n",
    "offstreet_parking = pd.read_csv(offstreet_parking_locations)\n",
    "private_garages = pd.read_csv(private_garage_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getll(x):\n",
    "    try:\n",
    "        x = x.split('\\n')[2]\n",
    "        x = re.sub(r'[\\(\\)]','',x)\n",
    "        x = x.split(', ')\n",
    "        return float(x[0]),float(x[1])\n",
    "    except AttributeError, IndexError:\n",
    "        return (None,None)\n",
    "\n",
    "parks['LatLon'] = parks['Location 1'].apply(getll)\n",
    "parks['X'] = parks['LatLon'].apply(lambda x: x[1])\n",
    "parks['Y'] = parks['LatLon'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read shapefiles and store properties into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:Fiona:Index: 0\n"
     ]
    }
   ],
   "source": [
    "def read_jobdensity():\n",
    "    ''' Process job density file into pandas dataframe '''\n",
    "    shp = fiona.open(shpfilename_jobdensity)\n",
    "    n = len(shp)\n",
    "    TRACT2010,\\\n",
    "    POP2010,\\\n",
    "    AREA_SMI,\\\n",
    "    JOBS_PSMI,\\\n",
    "    JOBS_CNT = \\\n",
    "        np.empty(n,dtype='|S25'),\\\n",
    "        np.empty(n,dtype='|S25'),\\\n",
    "        np.empty(n,dtype='|S25'),\\\n",
    "        np.empty(n,dtype='|S25'),\\\n",
    "        np.empty(n,dtype='|S25')\n",
    "    for i,s in enumerate(shp):\n",
    "        TRACT2010[i] = s['properties']['Tract2010']\n",
    "        POP2010 [i] = s['properties']['Pop2010']\n",
    "        AREA_SMI [i] = s['properties']['Area_smi']\n",
    "        JOBS_PSMI [i] = s['properties']['Jobs_psmi']\n",
    "        JOBS_CNT [i] = s['properties']['Jobs_cnt']\n",
    "    shp.close()\n",
    "    props_df = pd.DataFrame({\n",
    "            'Id':[i+1 for i in range(n)],\n",
    "            'TRACT2010':TRACT2010,\n",
    "            'POP2010':POP2010,\n",
    "            'AREA_SMI':AREA_SMI,\n",
    "            'JOBS_PSMI':JOBS_PSMI,\n",
    "            'JOBS_CNT':JOBS_CNT\n",
    "        })\n",
    "    return props_df\n",
    "\n",
    "props_df_jobs = read_jobdensity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_schoolfile():\n",
    "    ''' Process school file into pandas dataframe '''\n",
    "    shp = fiona.open(shpfilename_school)\n",
    "    n = len(shp)\n",
    "    SCHOOL_TYP,\\\n",
    "    DEPT,\\\n",
    "    FACILITY_N,\\\n",
    "    DEPTNAME,\\\n",
    "    FACILITY_I = \\\n",
    "        np.empty(n,dtype='|S25'),\\\n",
    "        np.empty(n,dtype='|S25'),\\\n",
    "        np.empty(n,dtype='|S25'),\\\n",
    "        np.empty(n,dtype='|S25'),\\\n",
    "        np.empty(n,dtype='|S25')\n",
    "    for i,s in enumerate(shp):\n",
    "        SCHOOL_TYP[i] = s['properties']['SCHOOL_TYP']\n",
    "        DEPT [i] = s['properties']['DEPT']\n",
    "        FACILITY_N [i] = s['properties']['FACILITY_N']\n",
    "        DEPTNAME [i] = s['properties']['DEPTNAME']\n",
    "        FACILITY_I [i] = s['properties']['FACILITY_I']\n",
    "    shp.close()\n",
    "    props_df = pd.DataFrame({\n",
    "            'Id':[i+1 for i in range(n)],\n",
    "            'SCHOOL_TYP':SCHOOL_TYP\n",
    "        })\n",
    "    return props_df\n",
    "\n",
    "props_df_schools = read_schoolfile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_zonefile():\n",
    "    ''' Process zones file into pandas dataframe '''\n",
    "    shp = fiona.open(shpfilename_zoning)\n",
    "    n = len(shp)\n",
    "    ZONING_SIM,\\\n",
    "    DISTRICTNA = \\\n",
    "        np.empty(n,dtype='|S25'),\\\n",
    "        np.empty(n,dtype='|S25')\n",
    "    for i,s in enumerate(shp):\n",
    "        ZONING_SIM[i] = s['properties']['ZONING_SIM']\n",
    "        DISTRICTNA[i] = s['properties']['DISTRICTNA']\n",
    "    shp.close()\n",
    "\n",
    "    props_df_zoning = pd.DataFrame({\n",
    "            'Id':[i+1 for i in range(n)],\n",
    "            'ZONING_SIM':ZONING_SIM,\n",
    "            'DISTRICTNA':DISTRICTNA\n",
    "        })\n",
    "\n",
    "props_df_zoning = read_zonefile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_electfile():\n",
    "    shp = fiona.open(shpfilename_elect)\n",
    "    n = len(shp)\n",
    "    kWh_pC,\\\n",
    "    kWh,\\\n",
    "    Zip,\\\n",
    "    Pop2010_zc = \\\n",
    "        np.empty(n,dtype=np.float64),\\\n",
    "        np.empty(n,dtype=np.float64),\\\n",
    "        np.empty(n,dtype='|S10'),\\\n",
    "        np.empty(n,dtype=np.int64)\n",
    "    for i,s in enumerate(shp):\n",
    "        kWh_pC[i] = s['properties']['kWh_pC']\n",
    "        kWh [i] = s['properties']['kWh']\n",
    "        Zip [i] = s['properties']['Zip']\n",
    "        Pop2010_zc [i] = s['properties']['Pop2010_zc']\n",
    "    shp.close()\n",
    "\n",
    "    props_df_elect = pd.DataFrame({\n",
    "            'Id':[i+1 for i in range(n)],\\\n",
    "            'kWh_pC':kWh_pC,\\\n",
    "            'kWh':kWh,\\\n",
    "            'Zip':Zip,\\\n",
    "            'Pop2010_zc':Pop2010_zc\\\n",
    "        })\n",
    "\n",
    "props_df_elect = read_electfile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_neighborhoods():\n",
    "    ''' Process school file into pandas dataframe '''\n",
    "    shp = fiona.open(shpfilename_neighborhoods)\n",
    "    n = len(shp)\n",
    "    NEIGHBORHOOD = \\\n",
    "        np.empty(n,dtype='|S25')\n",
    "    for i,s in enumerate(shp):\n",
    "        NEIGHBORHOOD[i] = s['properties']['neighborho']\n",
    "    shp.close()\n",
    "    props_df = pd.DataFrame({\n",
    "            'Id':[i+1 for i in range(n)],\n",
    "            'NEIGHBORHOOD':NEIGHBORHOOD\n",
    "        })\n",
    "    return props_df\n",
    "\n",
    "neighborhoods_df = read_neighborhoods()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_sdists():\n",
    "    ''' Process supervistoral district file into pandas dataframe '''\n",
    "    shp = fiona.open(shpfilename_sv_districts)\n",
    "    n = len(shp)\n",
    "    supname = \\\n",
    "        np.empty(n,dtype='|S25')\n",
    "    for i,s in enumerate(shp):\n",
    "        supname[i] = s['properties']['supname']\n",
    "    shp.close()\n",
    "    props_df = pd.DataFrame({\n",
    "            'Id':[i+1 for i in range(n)],\n",
    "            'supname':supname\n",
    "        })\n",
    "    return props_df\n",
    "\n",
    "sdist_df = read_sdists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Polygon search functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_poly_id(pl,x):\n",
    "        ''' Find the polygon within the \n",
    "            PolygonLocator that \n",
    "            matches to each point\n",
    "        '''\n",
    "        try:\n",
    "            return pl.contains_point(x)[0].id\n",
    "        except IndexError:\n",
    "            return -1\n",
    "\n",
    "def polygon_search(shpfilename,run_iters,\\\n",
    "                   pts,test=False,\\\n",
    "                   return_poly_id=return_poly_id):\n",
    "    ''' Iterate through shapefile polygons\n",
    "        and find id of polgy for each datapoint\n",
    "        \n",
    "        Need to create these functions:\n",
    "            1)a polygon match function\n",
    "                (above)\n",
    "            2)a run_iters function that \n",
    "                accepts a PolygonLocator object,\n",
    "                a polygon match function (above),\n",
    "                and a list of points to iterate over.         \n",
    "    '''\n",
    "    shp = pysal.open(shpfilename,'r')\n",
    "    pl = PolygonLocator([p for p in shp])\n",
    "    shp.close()\n",
    "    run_iters(pl,return_poly_id,pts,test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Coordinate search functions (faster than polygon search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coord_search(points, \\\n",
    "                 pl, \\\n",
    "                 run_iters_fun, \\\n",
    "                 locator_fun=BruteForcePointLocator):\n",
    "    ''' Since polygon search is not very efficient\n",
    "        when there are many polygons, instead\n",
    "        do a comparison to each polygon centroid \n",
    "    '''\n",
    "    gather_centroids = lambda shp: [p.centroid for p in shp]\n",
    "\n",
    "    # Read file\n",
    "    shp = pysal.open(shpfile,'r')\n",
    "    centroids = gather_centroids(shp)\n",
    "    pl = locator_fun(centroids)\n",
    "    shp.close()\n",
    "    \n",
    "    # Return the nearest points\n",
    "    nearest_ids = run_iters_fun(points,pl,centroids)\n",
    "    \n",
    "    return nearest_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coord_search_centroid(shpfile, points, \\\n",
    "                 run_iters_fun, \\\n",
    "                 locator_fun=BruteForcePointLocator):\n",
    "    ''' Since polygon search is not very efficient\n",
    "        when there are many polygons, instead\n",
    "        do a comparison to each polygon centroid \n",
    "    '''\n",
    "    gather_centroids = lambda shp: [p.centroid for p in shp]\n",
    "\n",
    "    # Read file\n",
    "    shp = pysal.open(shpfile,'r')\n",
    "    centroids = gather_centroids(shp)\n",
    "    pl = locator_fun(centroids)\n",
    "    shp.close()\n",
    "    \n",
    "    # Return the nearest points\n",
    "    nearest_ids = run_iters_fun(points,pl,centroids)\n",
    "    \n",
    "    return nearest_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Process to find nearby schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coord_search_schools(pts):\n",
    "    ''' Find nearest point and measure distance\n",
    "        for every datapoint \n",
    "    '''\n",
    "    hs = props_df_schools[props_df_schools['SCHOOL_TYP']=='High School']['Id']\n",
    "    cs = props_df_schools[props_df_schools['SCHOOL_TYP']=='County School']['Id']\n",
    "    chs = props_df_schools[props_df_schools['SCHOOL_TYP']=='Charter School']['Id']\n",
    "    ms = props_df_schools[props_df_schools['SCHOOL_TYP']=='Middle School']['Id']\n",
    "    \n",
    "    shp = pysal.open(shpfilename_school,'r')\n",
    "    pl_hs = BruteForcePointLocator([p for p in shp if p.id in hs])\n",
    "    pl_cs = BruteForcePointLocator([p for p in shp if p.id in cs])\n",
    "    pl_chs = BruteForcePointLocator([p for p in shp if p.id in chs])\n",
    "    pl_ms = BruteForcePointLocator([p for p in shp if p.id in ms])\n",
    "    shp.close()\n",
    "\n",
    "    return_point_hs = lambda x: pl_hs.nearest(x)\n",
    "    return_point_cs = lambda x: pl_cs.nearest(x)\n",
    "    return_point_chs = lambda x: pl_chs.nearest(x)\n",
    "    return_point_ms = lambda x: pl_ms.nearest(x)\n",
    "    \n",
    "    # point_ids = np.zeros(len(points),dtype=np.int8)\n",
    "    point_distances_hs = np.zeros(len(pts),dtype=np.float64)\n",
    "    point_distances_cs = np.zeros(len(pts),dtype=np.float64)\n",
    "    point_distances_chs = np.zeros(len(pts),dtype=np.float64)\n",
    "    point_distances_ms = np.zeros(len(pts),dtype=np.float64)\n",
    "    \n",
    "    def run_iters():\n",
    "        for i,p in enumerate(points):\n",
    "            if i%100000==0: print 'running {0} row'.format(i)\n",
    "            pt_hs = return_point_hs(p)\n",
    "            pt_cs = return_point_cs(p)\n",
    "            pt_chs = return_point_chs(p)\n",
    "            pt_ms = return_point_ms(p)\n",
    "            \n",
    "            point_distances_hs[i] = arcdist(p,pt_hs)\n",
    "            point_distances_cs[i] = arcdist(p,pt_cs)\n",
    "            point_distances_chs[i] = arcdist(p,pt_chs)\n",
    "            point_distances_ms[i] = arcdist(p,pt_ms)\n",
    "\n",
    "    run_iters()\n",
    "    \n",
    "    return point_distances_hs,\\\n",
    "            point_distances_cs,\\\n",
    "            point_distances_chs,\\\n",
    "            point_distances_ms\n",
    "\n",
    "'''            \n",
    "point_distances_hs,\\\n",
    "            point_distances_cs,\\\n",
    "            point_distances_chs,\\\n",
    "            point_distances_ms = coord_search_schools(points)\n",
    "test_point_distances_hs,\\\n",
    "            test_point_distances_cs,\\\n",
    "            test_point_distances_chs,\\\n",
    "            test_point_distances_ms = coord_search_schools(test_points)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions that iterate over each observation and match GIS data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_iters_points(points, point_locator, \\\n",
    "              proximity=100,log_at=100000):\n",
    "    ''' Iterate through points and return number\n",
    "        of points in surrounding proximity\n",
    "    '''\n",
    "    point_fun = lambda x,pl: pl.proximity(x,proximity)\n",
    "    surrounding_pts = np.zeros(len(points),dtype=np.int64)\n",
    "    for i,p in enumerate(points):\n",
    "        if i%log_at==0: logger.info('running {0} row'.format(i))\n",
    "        pts = point_fun(p,point_locator)\n",
    "        surrounding_pts[i] = len(pts)\n",
    "    return surrounding_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_iters_point_distance(points, point_locator\\\n",
    "            ,log_at=100000):\n",
    "    ''' Iterate through points and return distance\n",
    "        to the nearest point\n",
    "    '''\n",
    "    point_fun = lambda x,pl: pl.nearest(x)\n",
    "    distances = np.zeros(len(points),dtype=np.int64)\n",
    "    for i,p in enumerate(points):\n",
    "        if i%log_at==0: logger.info('running {0} row'.format(i))\n",
    "        pt = point_fun(p,point_locator)\n",
    "        distances[i] = arcdist(p,pt)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_iters_poly(plocator,return_poly_id,pts,test\\\n",
    "                   ,filename,dfname):\n",
    "    ''' Iterate through points and find matching polygon '''\n",
    "    poly_ids = np.zeros(len(pts),dtype=np.int8)\n",
    "    for i,p in enumerate(pts):\n",
    "        if i%100000==0: print 'running {0} row'.format(i)\n",
    "        poly_ids[i] = return_poly_id(plocator,p)\n",
    "    # Save data because this step takes >5hrs to finish\n",
    "    outname = filename.format('test_' if test else '')\n",
    "    poly_ids_df = pd.DataFrame({dfname:poly_ids})\n",
    "    poly_ids_df.to_csv(outname,index=False)\n",
    "\n",
    "'''\n",
    "polygon_search(shpfilename_elect,run_iters_poly,points,test=False\\\n",
    "    ,'Data/{}poly_ids2.csv','elect_poly_id')\n",
    "polygon_search(shpfilename_elect,run_iters_poly,test_points,test=True\\\n",
    "    ,'Data/{}poly_ids2.csv','elect_poly_id')\n",
    "polygon_search(shpfilename_zoning,run_iters_poly,points,test=False\\\n",
    "    ,'Data/{}zoning_ids.csv','zoning_id')\n",
    "polygon_search(shpfilename_zoning,run_iters_poly,test_points,test=True)\n",
    "    ,'Data/{}zoning_ids.csv','zoning_id')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_iters_centroid(points, point_locator, centroids, \\\n",
    "              log_at=100000):\n",
    "    ''' Iterate through points to find \n",
    "        the nearest matching polygon centroid point\n",
    "        \n",
    "        Faster than running polygon search \n",
    "    '''\n",
    "    point_fun = lambda x,pl: pl.nearest(x)\n",
    "    id_fun = lambda p, centroids: [i for i,c in enumerate(centroids)\\\n",
    "                                  if c==p][0]\n",
    "    nearest_ids = np.zeros(len(points),dtype=np.int64)\n",
    "    for i,p in enumerate(points):\n",
    "        if i%log_at==0: print 'running {0} row'.format(i)\n",
    "        pt = point_fun(p,point_locator)\n",
    "        pt_id = id_fun(pt, centroids)\n",
    "        nearest_ids[i] = pt_id\n",
    "    return nearest_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_file(array_to_save, colname, filename):\n",
    "    ''' Write column to CSV for use later '''\n",
    "    array_to_save_df = pd.DataFrame({colname:array_to_save})\n",
    "    array_to_save_df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create pooling function to distribute work over many cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_workload(worker,base_points,n_threads=2):\n",
    "    n = n_threads\n",
    "    pool = multiprocessing.Pool(n)\n",
    "    p = [ i*len(base_points)//n for i in range(n+1) ]\n",
    "\n",
    "    points_list = [ base_points[p[i]:p[i+1]] for i in range(n) ]\n",
    "    points_list += [base_points[p[n]:]]\n",
    "\n",
    "    res = pool.map(worker, points_list)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    x = pd.concat(res,axis=0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Process park CSV and find if park is nearby "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "park_points = [ Point((x,y)) for x,y in zip(trees['XCoord'],trees['YCoord']) ]\n",
    "def worker(points):\n",
    "    return pd.DataFrame({'trees':run_iters_point_distance(points\\\n",
    "                                  ,BruteForcePointLocator(park_points)\\\n",
    "                                  ,log_at=100000)})\n",
    "x = do_workload(worker,base_points,8)\n",
    "x.to_csv('Data/parks.csv')\n",
    "'''\n",
    "train_raw['parks'] = pd.read_csv('Data/parks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Process tree CSV and find number of trees nearby to crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "''' \n",
    "Run on another machine because it takes ~24 hours to run!\n",
    "tree_points = [ Point((x,y)) for x,y in zip(trees['XCoord'],trees['YCoord']) ]\n",
    "\n",
    "def worker(points):\n",
    "    return pd.DataFrame({'trees':run_iters_points(points\\\n",
    "                                  ,BruteForcePointLocator(tree_points)\\\n",
    "                                  ,proximity=100\n",
    "                                  ,log_at=1000)})\n",
    "\n",
    "x = do_workload(worker,base_points,8)\n",
    "x.to_csv('Data/trees.csv')\n",
    "'''\n",
    "train_raw['trees'] = pd.read_csv('Data/trees.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Process jobs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job_ids = coord_search_centroid(shpfilename_jobdensity,base_points,\\\n",
    "                        run_iters_centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "zone_ids = coord_search_centroid(shpfilename_zoning,base_points,\\\n",
    "                        run_iters_centroid)\n",
    "save_file(zone_ids, 'zoning_id', 'Data/zoning_ids2.csv')\n",
    "\n",
    "test_zone_ids = coord_search_centroid(shpfilename_zoning,test_points,\\\n",
    "                         run_iters_centroid)\n",
    "save_file(test_zone_ids, 'zoning_id', 'Data/test_zoning_ids2.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load data from saved files after they've already been processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data fr\n",
    "zone_ids = pd.read_csv('Data/zoning_ids.csv')\n",
    "test_zone_ids = pd.read_csv('Data/test_zoning_ids.csv')\n",
    "all_zones = pd.merge(zone_ids,props_df_zoning,'left',\\\n",
    "                    left_on=['zoning_id'], right_on=['Id'])\n",
    "test_all_zones = pd.merge(test_zone_ids,props_df_zoning,'left',\\\n",
    "                    left_on=['zoning_id'], right_on=['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only run this after ids are compiled\n",
    "poly_ids_df_elect = pd.read_csv('Data/poly_ids.csv')\n",
    "test_poly_ids_df_elect = pd.read_csv('Data/test_poly_ids.csv')\n",
    "all_elects = pd.merge(poly_ids_df_elect, props_df_elect, 'left',\\\n",
    "                     left_on=['elect_poly_id'], right_on=['Id'])\n",
    "test_elects = pd.merge(test_poly_ids_df_elect, props_df_elect, 'left',\\\n",
    "                     left_on=['elect_poly_id'], right_on=['Id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elect_cols = ['kWh_pC','kWh','Zip','Pop2010_zc']\n",
    "train_raw[elect_cols] = all_elects[elect_cols] \n",
    "test_raw[elect_cols] = test_elects[elect_cols] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# School features had little/no effect on the model\n",
    "# school_nearby = np.vectorize(lambda x: True if x<=1000 else False)\n",
    "# train_raw['HS_DISTANCE'] = point_distances_hs.astype(np.float64)\n",
    "# train_raw['CS_DISTANCE'] = point_distances_cs.astype(np.float64)\n",
    "# train_raw['CHS_DISTANCE'] = point_distances_chs.astype(np.float64)\n",
    "# train_raw['MS_DISTANCE'] = point_distances_ms.astype(np.float64)\n",
    "# train_raw['HS_NEARBY'] = school_nearby(train_raw['HS_DISTANCE'])\n",
    "# train_raw['CS_NEARBY'] = school_nearby(train_raw['CS_DISTANCE'])\n",
    "# train_raw['CHS_NEARBY'] = school_nearby(train_raw['CHS_DISTANCE'])\n",
    "# train_raw['MS_NEARBY'] = school_nearby(train_raw['MS_DISTANCE'])\n",
    "\n",
    "# test_raw['HS_DISTANCE'] = test_point_distances_hs.astype(np.float64)\n",
    "# test_raw['CS_DISTANCE'] = test_point_distances_cs.astype(np.float64)\n",
    "# test_raw['CHS_DISTANCE'] = test_point_distances_chs.astype(np.float64)\n",
    "# test_raw['MS_DISTANCE'] = test_point_distances_ms.astype(np.float64)\n",
    "# test_raw['HS_NEARBY'] = school_nearby(test_raw['HS_DISTANCE'])\n",
    "# test_raw['CS_NEARBY'] = school_nearby(test_raw['CS_DISTANCE'])\n",
    "# test_raw['CHS_NEARBY'] = school_nearby(test_raw['CHS_DISTANCE'])\n",
    "# test_raw['MS_NEARBY'] = school_nearby(test_raw['MS_DISTANCE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_raw['ZONING_SIM'] = all_zones['ZONING_SIM']\n",
    "train_raw['DISTRICT_NAME'] = all_zones['DISTRICTNA']\n",
    "train_raw['ZONE_ID'] = all_zones['Id']\n",
    "\n",
    "test_raw['ZONING_SIM'] = test_all_zones['ZONING_SIM']\n",
    "test_raw['DISTRICT_NAME'] = test_all_zones['DISTRICTNA']\n",
    "test_raw['ZONE_ID'] = test_all_zones['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_fields = [\n",
    "    'PdDistrict','DaySegment','DayOfWeek','AddressMod'\\\n",
    "    ,'DayOfMonth','YearQtr','KMcluster','KMdistance','trees'\n",
    "]\n",
    "cat_fields = [\n",
    "    'PdDistrict','YearQtr','Year','DayOfWeek','DaySegment','TimeOfDay'\\\n",
    "    ,'DayOfMonth','YearSegment','KMcluster','AddressMod'\\\n",
    "    ,'collar_id','Category'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_knnguess():\n",
    "    knn = KNeighborsClassifier(n_neighbors=20)\n",
    "    le = MultiColumnLabelEncoder()\n",
    "    imp = Imputer(strategy='mean')\n",
    "    cf = [i for i,x in enumerate(new_fields) if x in cat_fields]\n",
    "    ohe = OneHotEncoder(categorical_features=cf,sparse=True)\n",
    "    svd = TruncatedSVD(n_components=20) \n",
    "    pl = Pipeline([('le',le),('ohe',ohe),('svd',svd),('md',md)])\n",
    "    \n",
    "    pl.fit(dev_train, dev_train_labels)\n",
    "    train_raw['KNNguess'] = pl.predict(train_raw[new_fields])\n",
    "    test_raw['KNNguess'] = pl.predict(test_raw[new_fields])\n",
    "\n",
    "add_knnguess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Model for collar_id started\n",
      "INFO:root:Sampling started\n",
      "INFO:root:Fitting training data\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "bad input shape (868048, 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-259-9e19c21b1c39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model for collar_id started'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mpl_metaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_metaclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model for collar_id ended'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-259-9e19c21b1c39>\u001b[0m in \u001b[0;36mpredict_metaclass\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# Fit training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fitting training data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_train_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# Show results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mthe\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \"\"\"\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pre_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36m_pre_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-235-76e29e1e8fe0>\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-235-76e29e1e8fe0>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0;32mpass\u001b[0m \u001b[0;31m# leave integers alone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/preprocessing/label.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \"\"\"\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0m_check_numpy_unicode_bug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: bad input shape (868048, 9)"
     ]
    }
   ],
   "source": [
    "def predict_metaclass():\n",
    "    '''Predict the metaclass of crime\n",
    "       Use the outputted algorithm to \n",
    "       predict metaclass in the training data\n",
    "    '''\n",
    "    logger.info('Sampling started')\n",
    "    \n",
    "    '''Alternate sampling method\n",
    "    tr = sample_df(train_raw[new_fields+['collar_id','Category']]\\\n",
    "                                    ,'Category'\\\n",
    "                                     ,set(train_raw['Category'])\\\n",
    "                                      ,group_n=200000\\\n",
    "                                       ,group_cnts=group_cnts\\\n",
    "                                         ,nX=20)\n",
    "    \n",
    "    '''\n",
    "    tr = train_raw[new_fields+['collar_id','Category']].copy().iloc[\\\n",
    "                   np.random.permutation(len(train_raw))]\n",
    "    \n",
    "    dev_train, dev_train_labels = tr[new_fields][10001:],\\\n",
    "                           tr['collar_id'][10001:]\n",
    "    dev_test, dev_test_labels = tr[new_fields][:10000],\\\n",
    "                            tr['collar_id'][:10000]\n",
    "    \n",
    "    # Create pipeline\n",
    "    le = MultiColumnLabelEncoder()\n",
    "    cf = [i for i,x in enumerate(new_fields) if x in cat_fields]\n",
    "    ohe = OneHotEncoder(categorical_features=cf,sparse=True)\n",
    "    imp = Imputer()\n",
    "    ''' Alternative classifiers\n",
    "    md = OneVsRestClassifier(MultinomialNB(alpha=0.01))'''\n",
    "    md = LogisticRegression(C=0.1,solver='lbfgs',\\\n",
    "                            multi_class='multinomial',tol=0.01)\n",
    "    svd = TruncatedSVD(n_components=20) \n",
    "    pl = Pipeline([('le',le),('ohe',ohe),('imp',imp),('svd',svd),('md',md)])\n",
    "    \n",
    "    ''' GridSearch for optimal parameters\n",
    "    logger.info('GV search started')\n",
    "    param_grid = dict(md__C=[0.1,0.5,1,5])\n",
    "    gs = GridSearchCV(pl, param_grid=param_grid, verbose=10)\n",
    "    gs.fit(dev_train, dev_train_labels)\n",
    "    logger.info('Best C parameter: {}'.format(gs.best_estimator_)) \n",
    "    logger.info('GV search ended')\n",
    "    '''\n",
    "    \n",
    "    # Fit training data \n",
    "    logger.info('Fitting training data') \n",
    "    pl.fit(dev_train, dev_train_labels)\n",
    "    \n",
    "    # Show results\n",
    "    print 'Model accuracy: {}%'.format(round(pl.score(dev_test, \\\n",
    "                                                 dev_test_labels),4)*100)\n",
    "    logger.info('Model diagnostics started')\n",
    "    predictions = pl.predict(dev_test)\n",
    "    conf = confusion_matrix(dev_test_labels,predictions)\n",
    "    plt.imshow(conf, cmap='binary',interpolation='nearest')\n",
    "    print pd.crosstab(dev_test_labels, predictions, \\\n",
    "                      rownames=['True'], colnames=['Predicted'], \\\n",
    "                      margins=True)\n",
    "    \n",
    "    # Return model and datasets for later use\n",
    "    return pl, (dev_train,dev_train_labels,dev_test,dev_test_labels)\n",
    "\n",
    "logger.info('Model for collar_id started')\n",
    "pl_metaclass, new_datasets = predict_metaclass()\n",
    "logger.info('Model for collar_id ended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_train,dev_train_labels,dev_test,dev_test_labels = new_datasets\n",
    "print 'F1 Score: {}%'.format(round(f1_score(\\\n",
    "                    pl_metaclass.predict(dev_test)\\\n",
    "                    ,dev_test_labels\\\n",
    "                    ,average='weighted')*100,2))\n",
    "print classification_report(pl_metaclass.predict(dev_test)\\\n",
    "                    ,dev_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add prediction and prediction score as a feature\n",
    "\n",
    "Use the generated dev and test datasets from above in future modeling efforts, because otherwise the model will have been fit with test data and accuracy measures will have been thrown off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_fields = [\n",
    "        'PdDistrict','DaySegment','DayOfWeek','AddressMod'\\\n",
    "        ,'DayOfMonth','Year','YearSegment'\\\n",
    "        ,'KMcluster','KMdistance'\n",
    "    ]\n",
    "le,ohe,md = [ x[1] for x in pl_metaclass.steps[:3] ]\n",
    "tr = le.transform(train_raw[new_fields])\n",
    "tr = ohe.transform(tr)\n",
    "train_raw['cid_pred_score'] = \\\n",
    "    #np.max(md.decision_function(tr),axis=1)\n",
    "    np.max(md.predict_proba(tr),axis=1)\n",
    "train_raw['cid_prediction'] = pl_metaclass.predict(tr) # overfit\n",
    " \n",
    "tr = le.transform(test_raw[new_fields])\n",
    "tr = ohe.transform(tr)\n",
    "test_raw['cid_pred_score'] = \\\n",
    "    #np.max(md.decision_function(tr),axis=1)\n",
    "    np.max(md.predict_proba(tr),axis=1)\n",
    "test_raw['cid_prediction'] = pl_metaclass.predict(tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_fields = [\n",
    "    'PdDistrict','DaySegment',\\\n",
    "    'kWh','Zip','Pop2010_zc','Year','KMcluster'\n",
    "]\n",
    "cat_fields = [\n",
    "    'PdDistrict','DayOfWeek','DaySegment','TimeOfDay','DayOfMonth','Year',\\\n",
    "    'Zip','KMcluster',\\\n",
    "    'ZONING_SIM','DISTRICT_NAME','ZONE_ID'\n",
    "]\n",
    "train_raw = train_raw.iloc[\\\n",
    "                    np.random.permutation(len(train_raw))]\n",
    "dev_train, dev_train_labels = train_raw[new_fields][10001:],\\\n",
    "                        train_raw['Category'][10001:]\n",
    "dev_train_weights = np.array(train_raw['sample_weight'][10001:])\n",
    "dev_test, dev_test_labels = train_raw[new_fields][:10000],\\\n",
    "                        train_raw['Category'][:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def runmodel():\n",
    "    new_fields = [\n",
    "        'PdDistrict','DaySegment',\\\n",
    "        'kWh','Zip','Pop2010_zc','Year','KMcluster'\n",
    "    ]\n",
    "    cat_fields = [\n",
    "        'PdDistrict','DayOfWeek','DaySegment','TimeOfDay','DayOfMonth','Year',\\\n",
    "        'Zip','KMcluster',\\\n",
    "        'ZONING_SIM','DISTRICT_NAME','ZONE_ID','KNNguess'\n",
    "    ]\n",
    "\n",
    "    le = MultiColumnLabelEncoder()\n",
    "    imp = Imputer(strategy='mean')\n",
    "    cf = [i for i,x in enumerate(new_fields) if x in cat_fields]\n",
    "    ohe = OneHotEncoder(categorical_features=cf,sparse=True)\n",
    "    pca = PCA(n_components = 100)\n",
    "    #md = MultinomialNB(alpha=0.01)\n",
    "    md = LogisticRegression(C=0.1,solver='lbfgs',\\\n",
    "                            multi_class='multinomial')\n",
    "    pl = Pipeline([('le',le), ('imp',imp), ('ohe', ohe), ('pca',pca), ('rf', rf)])\n",
    "\n",
    "    pl.fit(dev_train, dev_train_labels,rf__sample_weight=dev_train_weights)\n",
    "    print 'Accuracy: {0}%'.format(round(pl.score(dev_test, dev_test_labels),4)*100)\n",
    "    return pl \n",
    "\n",
    "# pl = runmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_pca():\n",
    "    exp_var = np.cumsum(pl.named_steps['pca'].explained_variance_ratio_)\n",
    "    n = len(exp_var)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title('PCA explained variance')\n",
    "    ax.set_xlabel('Feature number')\n",
    "    ax.set_ylabel('Explained Variance')\n",
    "    ax.plot(range(n),exp_var,'-', linewidth=2)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# show_pca()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Make another submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_testdata():\n",
    "    test_raw.to_csv('Data/test_raw_nf.csv',index=False)\n",
    "\n",
    "# save_testdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predictions = pl.predict(test_raw[new_fields])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_to_submissionfile():\n",
    "    l = len(test_raw)\n",
    "    submission = np.zeros((l,40),dtype=np.int32)\n",
    "    submission[:,0] = range(l)\n",
    "    cols = sorted(set(train_raw['Category']))\n",
    "    for i,c in enumerate(cols):\n",
    "        submission[:,i+1] = predictions == c\n",
    "\n",
    "    submission_cols = ['Id']\n",
    "    submission_cols.extend(cols)\n",
    "    submission_df = pd.DataFrame(submission,columns=submission_cols)\n",
    "    submission_df.head()\n",
    "\n",
    "    submission_df.to_csv('Data/submission_file2.csv',index=False)\n",
    "    \n",
    "# write_to_submissionfile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Part 3 - Error Diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = pl.predict(dev_test)\n",
    "conf = confusion_matrix(dev_test_labels,predictions)\n",
    "plt.imshow(conf, cmap='binary')\n",
    "pd.crosstab(dev_test_labels, predictions, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appendix: Cheaters\n",
    "\n",
    "Virtually all of the test dataset is available publicly online, with a holdout of only ~70k records. My thoughts are that the competition conductors will test using data from the holdout set (or else they are very silly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_raw_clean = test_raw.drop_duplicates()\n",
    "crimes = pd.read_csv('/Users/bshur/School/\\\n",
    "Machine Learning/Final Project/Data/\\\n",
    "SFPD_Incidents_-_from_1_January_2003.csv')\n",
    "crimes['Dates'] = pd.to_datetime(crimes['Date']\\\n",
    "                                 +' '\\\n",
    "                                 +crimes['Time']\\\n",
    "                                 ,format='%m/%d/%Y %H:%M')\n",
    "crimes_cleaned = crimes[['Dates','DayOfWeek'\\\n",
    "                         ,'PdDistrict','Address'\\\n",
    "                         ,'X','Y']].drop_duplicates()\n",
    "crimes_matched = pd.merge(crimes_cleaned\\\n",
    "                          ,test_raw_clean\\\n",
    "                          ,how='inner'\n",
    "                          ,on=['Dates','DayOfWeek'\\\n",
    "                               ,'PdDistrict','Address'\\\n",
    "                               ,'X','Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set count: 884262\n",
      "Matched set count: 815740\n",
      "Difference: 68522\n"
     ]
    }
   ],
   "source": [
    "print 'Test set count: {}\\nMatched set count: {}\\nDifference: {}'.format(\\\n",
    "                            test_raw_clean.shape[0]\\\n",
    "                            ,crimes_matched.shape[0]\\\n",
    "                            ,test_raw_clean.shape[0]\\\n",
    "                              -crimes_matched.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

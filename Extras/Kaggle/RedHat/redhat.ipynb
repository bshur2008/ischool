{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RedHat Kaggle\n",
    "\n",
    "https://www.kaggle.com/c/predicting-red-hat-business-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import multiprocessing\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "CPUS = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CPUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_col(x, p):\n",
    "    if type(x)==str:\n",
    "        return p+'_'+x.replace(' ','_')\n",
    "    else:\n",
    "        return p+'_'+str(x)\n",
    "\n",
    "def update_cols(df,c=1):\n",
    "    # fix date columns\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    del df['date']\n",
    "    \n",
    "    # get list of columns\n",
    "    cols = list(df.columns)\n",
    "    \n",
    "    # include column name with value\n",
    "    for p in cols[c:]:\n",
    "        df.loc[:,p] = df.loc[:,p].apply(lambda x: format_col(x, p) )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_scores(y_test, predictions, pr=True):\n",
    "    ll = log_loss(y_test, predictions)\n",
    "    a = accuracy_score(y_test, np.argmax(predictions,axis=1))\n",
    "    auc = roc_auc_score(np.c_[y_test==0, y_test==1], predictions)\n",
    "    r = {'c':c,'logloss':ll,'accuracy':a,'AUC':auc}\n",
    "    pstr = '''C:{c} Log-Loss:{logloss:.7f} Accuracy:{accuracy:.7f} AUC:{AUC:.7f}'''\n",
    "    if pr: print pstr.format(**r)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_sparse_data(df, ohe_dict):\n",
    "    rows = []\n",
    "    cols = []\n",
    "    data = []\n",
    "    for i in xrange(df.shape[0]):\n",
    "        s = map(lambda x: ohe_dict.get(x,-1), df.iloc[i])\n",
    "        while True:\n",
    "            if -1 in s:\n",
    "                indval = s.index(-1)\n",
    "                del s[indval]\n",
    "            else:\n",
    "                break\n",
    "        rows += [i]*len(s)\n",
    "        cols += s\n",
    "        data += [1]*len(s)\n",
    "    return csr_matrix((np.array(data),\n",
    "                (np.array(rows),\n",
    "                 np.array(cols))),\n",
    "               shape=(df.shape[0],len(ohe_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_missing_val_lookup(df):\n",
    "    mode_str = lambda x: Counter(list(x)).most_common(1)[0][0]\n",
    "    char_cols = [ c for c in list(df.columns) if re.search('char_',c)]\n",
    "\n",
    "    def find_char_modes(df, char_cols):\n",
    "        for char_col in char_cols:\n",
    "            nonnulls = df[char_col].apply(lambda x: str(x).lower()!='nan')\n",
    "            char_r = df.loc[nonnulls, char_col].groupby(level=0).apply(mode_str)\n",
    "            yield char_r\n",
    "\n",
    "    def find_mode_overall(df, char_cols):\n",
    "        for char_col in char_cols:\n",
    "            nonnulls = df[char_col].apply(lambda x: str(x).lower()!='nan')\n",
    "            freq_val = df.loc[nonnulls, char_col].reset_index().apply(mode_str)[char_col]\n",
    "            yield freq_val\n",
    "\n",
    "    # find most common result for each column-person\n",
    "    char_col_results = find_char_modes(df, char_cols)\n",
    "\n",
    "    # find most common result overall for each column\n",
    "    freq_results = find_mode_overall(df, char_cols)\n",
    "\n",
    "    # create lookup table for missing values\n",
    "    missing_val_lookup = pd.DataFrame(pd.concat(char_col_results, axis=1), columns=char_cols)\n",
    "    freq_lookup = pd.DataFrame(freq_results, index=char_cols, columns=['most_freq'])\n",
    "    freq_lookup_dict = freq_lookup.to_dict()['most_freq']\n",
    "    missing_val_lookup = missing_val_lookup.fillna(freq_lookup_dict, axis=0)\n",
    "    \n",
    "    return missing_val_lookup, freq_lookup_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DIR = '/'\n",
    "FTRAIN = 'Data/act_train.csv.gz'\n",
    "FTEST = 'Data/act_test.csv.gz'\n",
    "FPEOPLE = 'Data/people.csv.gz'\n",
    "FSAMPLE = 'Data/sample_submission.csv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv(DIR+FTRAIN)\n",
    "test_raw = pd.read_csv(DIR+FTEST)\n",
    "people = pd.read_csv(DIR+FPEOPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = train_raw['outcome']\n",
    "del train_raw['outcome']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = Y.value_counts()*1.0 / train_raw.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = train_raw.shape[0]\n",
    "predictions = np.zeros((N,2))\n",
    "for i in xrange(N):\n",
    "    predictions[i,:] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55604560342712916"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y, np.argmax(predictions,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68685173924161147"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(Y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(np.c_[Y==0,Y==1], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Handle null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people_id</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>date</th>\n",
       "      <th>activity_category</th>\n",
       "      <th>char_1</th>\n",
       "      <th>char_2</th>\n",
       "      <th>char_3</th>\n",
       "      <th>char_4</th>\n",
       "      <th>char_5</th>\n",
       "      <th>char_6</th>\n",
       "      <th>char_7</th>\n",
       "      <th>char_8</th>\n",
       "      <th>char_9</th>\n",
       "      <th>char_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2197291</td>\n",
       "      <td>2197291</td>\n",
       "      <td>2197291</td>\n",
       "      <td>2197291</td>\n",
       "      <td>157615</td>\n",
       "      <td>157615</td>\n",
       "      <td>157615</td>\n",
       "      <td>157615</td>\n",
       "      <td>157615</td>\n",
       "      <td>157615</td>\n",
       "      <td>157615</td>\n",
       "      <td>157615</td>\n",
       "      <td>157615</td>\n",
       "      <td>2039676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>151295</td>\n",
       "      <td>2197291</td>\n",
       "      <td>411</td>\n",
       "      <td>7</td>\n",
       "      <td>51</td>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>6515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ppl_294918</td>\n",
       "      <td>act2_979099</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>type 2</td>\n",
       "      <td>type 2</td>\n",
       "      <td>type 2</td>\n",
       "      <td>type 1</td>\n",
       "      <td>type 3</td>\n",
       "      <td>type 6</td>\n",
       "      <td>type 2</td>\n",
       "      <td>type 1</td>\n",
       "      <td>type 4</td>\n",
       "      <td>type 8</td>\n",
       "      <td>type 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>55103</td>\n",
       "      <td>1</td>\n",
       "      <td>48174</td>\n",
       "      <td>904683</td>\n",
       "      <td>38030</td>\n",
       "      <td>50524</td>\n",
       "      <td>38224</td>\n",
       "      <td>98131</td>\n",
       "      <td>67989</td>\n",
       "      <td>61026</td>\n",
       "      <td>52548</td>\n",
       "      <td>77460</td>\n",
       "      <td>31794</td>\n",
       "      <td>904683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         people_id  activity_id        date activity_category  char_1  char_2  \\\n",
       "count      2197291      2197291     2197291           2197291  157615  157615   \n",
       "unique      151295      2197291         411                 7      51      32   \n",
       "top     ppl_294918  act2_979099  2022-09-30            type 2  type 2  type 2   \n",
       "freq         55103            1       48174            904683   38030   50524   \n",
       "\n",
       "        char_3  char_4  char_5  char_6  char_7  char_8  char_9  char_10  \n",
       "count   157615  157615  157615  157615  157615  157615  157615  2039676  \n",
       "unique      11       7       7       5       8      18      19     6515  \n",
       "top     type 1  type 3  type 6  type 2  type 1  type 4  type 8   type 1  \n",
       "freq     38224   98131   67989   61026   52548   77460   31794   904683  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people_id</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>date</th>\n",
       "      <th>activity_category</th>\n",
       "      <th>char_1</th>\n",
       "      <th>char_2</th>\n",
       "      <th>char_3</th>\n",
       "      <th>char_4</th>\n",
       "      <th>char_5</th>\n",
       "      <th>char_6</th>\n",
       "      <th>char_7</th>\n",
       "      <th>char_8</th>\n",
       "      <th>char_9</th>\n",
       "      <th>char_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>498687</td>\n",
       "      <td>498687</td>\n",
       "      <td>498687</td>\n",
       "      <td>498687</td>\n",
       "      <td>40092</td>\n",
       "      <td>40092</td>\n",
       "      <td>40092</td>\n",
       "      <td>40092</td>\n",
       "      <td>40092</td>\n",
       "      <td>40092</td>\n",
       "      <td>40092</td>\n",
       "      <td>40092</td>\n",
       "      <td>40092</td>\n",
       "      <td>458595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>37823</td>\n",
       "      <td>498687</td>\n",
       "      <td>411</td>\n",
       "      <td>7</td>\n",
       "      <td>48</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>3961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ppl_112017</td>\n",
       "      <td>act2_2659718</td>\n",
       "      <td>2022-09-16</td>\n",
       "      <td>type 2</td>\n",
       "      <td>type 2</td>\n",
       "      <td>type 2</td>\n",
       "      <td>type 1</td>\n",
       "      <td>type 3</td>\n",
       "      <td>type 6</td>\n",
       "      <td>type 2</td>\n",
       "      <td>type 1</td>\n",
       "      <td>type 4</td>\n",
       "      <td>type 8</td>\n",
       "      <td>type 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1650</td>\n",
       "      <td>1</td>\n",
       "      <td>10302</td>\n",
       "      <td>223164</td>\n",
       "      <td>9862</td>\n",
       "      <td>12757</td>\n",
       "      <td>9927</td>\n",
       "      <td>25046</td>\n",
       "      <td>17131</td>\n",
       "      <td>15940</td>\n",
       "      <td>13290</td>\n",
       "      <td>19803</td>\n",
       "      <td>7888</td>\n",
       "      <td>223164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         people_id   activity_id        date activity_category  char_1  \\\n",
       "count       498687        498687      498687            498687   40092   \n",
       "unique       37823        498687         411                 7      48   \n",
       "top     ppl_112017  act2_2659718  2022-09-16            type 2  type 2   \n",
       "freq          1650             1       10302            223164    9862   \n",
       "\n",
       "        char_2  char_3  char_4  char_5  char_6  char_7  char_8  char_9 char_10  \n",
       "count    40092   40092   40092   40092   40092   40092   40092   40092  458595  \n",
       "unique      31      11       7       6       5       8      18      19    3961  \n",
       "top     type 2  type 1  type 3  type 6  type 2  type 1  type 4  type 8  type 1  \n",
       "freq     12757    9927   25046   17131   15940   13290   19803    7888  223164  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_raw.index = train_raw['people_id']\n",
    "test_raw.index = test_raw['people_id']\n",
    "people.index = people['people_id']\n",
    "del train_raw['people_id']\n",
    "del test_raw['people_id']\n",
    "del people['people_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "people_lookup, freq_lookup = create_missing_val_lookup(train_raw)\n",
    "train_raw = train_raw.fillna( people_lookup, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_raw = test_raw.fillna( people_lookup, axis=0 )\n",
    "test_raw = test_raw.fillna( freq_lookup, axis=0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature updates for sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percentile_ref = people['char_38'].ravel()\n",
    "compare_percentile = lambda x: round(sp.stats.percentileofscore(percentile_ref, x, kind='weak'),-1)\n",
    "people['char_38'] = people['char_38'].apply(compare_percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "people = update_cols(people, 0)\n",
    "train_raw = update_cols(train_raw, 1)\n",
    "test_raw = update_cols(test_raw, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform data to sparse OHE matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_full = pd.merge(train_raw, people, left_index=True, right_index=True)\n",
    "test_full = pd.merge(test_raw, people, left_index=True, right_index=True)\n",
    "train_full.index = train_full['activity_id']\n",
    "test_full.index = test_full['activity_id']\n",
    "del train_full['activity_id']\n",
    "del test_full['activity_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93315234035253525"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_full.memory_usage())*1.0/1024**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21178393810987473"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_full.memory_usage())*1.0/1024**3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create OHE dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_values = np.unique(train_full.as_matrix().reshape(1,-1).ravel())\n",
    "ohe_dict= { k: v for k,v in zip(all_values, xrange(all_values.shape[0])) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create sparse matrices for test and training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = create_sparse_data(train_full, ohe_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = create_sparse_data(test_full, ohe_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IDs = np.array(test_full.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clear unused memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del train_full \n",
    "del train_raw\n",
    "del test_full\n",
    "del test_raw\n",
    "del ohe_dict\n",
    "del all_values\n",
    "del people "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, \n",
    "                                                  Y, \n",
    "                                                  test_size=0.20, \n",
    "                                                  random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:10.0 Log-Loss:0.0677318 Accuracy:0.9720019 AUC:0.9971554\n",
      "C:100.0 Log-Loss:0.0648277 Accuracy:0.9718040 AUC:0.9972451\n",
      "C:1000.0 Log-Loss:0.0656197 Accuracy:0.9716629 AUC:0.9972100\n"
     ]
    }
   ],
   "source": [
    "cvalues = [ 1e1, 1e2, 1e3 ]\n",
    "results = []\n",
    "for c in cvalues:\n",
    "    lr = LogisticRegression(C=c, max_iter=500, tol=1e-5, n_jobs=CPUS)\n",
    "    lr.fit(X_train, y_train)\n",
    "    predictions = lr.predict_proba(X_val)\n",
    "    r = test_scores(y_val, predictions)\n",
    "    results.append(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = 1e2\n",
    "lr = LogisticRegression(C=c, max_iter=500, tol=1e-5, n_jobs=CPUS)\n",
    "lr.fit(X, Y)\n",
    "predictions = lr.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(np.vstack((IDs, \n",
    "                                     predictions[:,1])).T,\n",
    "                          columns=['activity_id','outcome'])\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!gzip submission.csv\n",
    "!s3put -bbrandonshurick -p/home/ubuntu/ -gpublic-read submission.csv.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_scores_xgb(y_val, predictions):\n",
    "    pfull = np.c_[1-predictions,predictions]\n",
    "    ll = log_loss(y_val, pfull)\n",
    "    a = accuracy_score(y_val, np.argmax(pfull ,axis=1))\n",
    "    auc = roc_auc_score(np.c_[y_val==0, y_val==1], pfull)\n",
    "    r = {'logloss':ll,'accuracy':a,'AUC':auc}\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix( X_train, label=y_train.as_matrix() )\n",
    "dval = xgb.DMatrix( X_val, label=y_val.as_matrix() )\n",
    "dtest = xgb.DMatrix( X_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.986746\ttrain-auc:0.989671\n",
      "[50]\teval-auc:0.997443\ttrain-auc:0.998835\n"
     ]
    }
   ],
   "source": [
    "d = 500\n",
    "e = 0.01\n",
    "param = {'max_depth':d, \n",
    "         'eta':e, \n",
    "         'subsample':0.5, \n",
    "         'colsample_bytree':0.75,\n",
    "         'colsample_bylevel':0.75,\n",
    "         'silent':1, \n",
    "         'objective':'binary:logistic' }\n",
    "param['eval_metric'] = 'auc'\n",
    "param['nthread'] = CPUS\n",
    "evallist  = [(dval,'eval'), (dtrain,'train')]\n",
    "xgb_model = xgb.train(param.items(), dtrain, 501, evallist, verbose_eval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = xgb_model.predict( dval )\n",
    "test_scores_xgb(y_val, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = xgb_model.predict( dtest )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(np.vstack((IDs, \n",
    "                                     predictions)).T,\n",
    "                          columns=['activity_id','outcome'])\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!gzip submission.csv !s3put -bbrandonshurick -p/home/ubuntu/ -gpublic-read submission.csv.gz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import multiprocessing\n",
    "\n",
    "CPUS = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CPUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DIR = '/'\n",
    "FTRAIN = 'Data/act_train.csv.gz'\n",
    "FTEST = 'Data/act_test.csv.gz'\n",
    "FPEOPLE = 'Data/people.csv.gz'\n",
    "FSAMPLE = 'Data/sample_submission.csv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv(DIR+FTRAIN)\n",
    "test_raw = pd.read_csv(DIR+FTEST)\n",
    "people = pd.read_csv(DIR+FPEOPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = train_raw['outcome']\n",
    "del train_raw['outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = Y.value_counts()*1.0 / train_raw.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = train_raw.shape[0]\n",
    "predictions = np.zeros((N,2))\n",
    "for i in xrange(N):\n",
    "    predictions[i,:] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy_score(Y, np.argmax(predictions,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_loss(Y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roc_auc_score(np.c_[Y==0,Y==1], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature updates for sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "percentile_ref = people['char_38'].ravel()\n",
    "compare_percentile = lambda x: round(sp.stats.percentileofscore(percentile_ref, x, kind='weak'),-1)\n",
    "people['char_38'] = people['char_38'].apply(compare_percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_col(x, p):\n",
    "    if type(x)==str:\n",
    "        return p+'_'+x.replace(' ','_')\n",
    "    else:\n",
    "        return p+'_'+str(x)\n",
    "\n",
    "def update_cols(df,c=1):\n",
    "    # fix date columns\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    del df['date']\n",
    "    \n",
    "    # get list of columns\n",
    "    cols = list(df.columns)\n",
    "    \n",
    "    # include column name with value\n",
    "    for p in cols[c:]:\n",
    "        df.loc[:,p] = df.loc[:,p].apply(lambda x: format_col(x, p) )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "people = update_cols(people, 1)\n",
    "train_raw = update_cols(train_raw, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_raw.index = train_raw['people_id']\n",
    "people.index = people['people_id']\n",
    "del train_raw['people_id']\n",
    "del people['people_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform data to sparse OHE matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_full = pd.merge(train_raw, people, left_index=True, right_index=True)\n",
    "train_full.index = train_full['activity_id']\n",
    "del train_full['activity_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(train_full.memory_usage())*1.0/1024**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_values = np.unique(train_full.as_matrix().reshape(1,-1).ravel())\n",
    "ohe_dict= { k: v for k,v in zip(all_values, xrange(all_values.shape[0])) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "cols = []\n",
    "data = []\n",
    "for i in xrange(train_full.shape[0]):\n",
    "    s = map(lambda x: ohe_dict[x], train_full.iloc[i])\n",
    "    rows += [i]*len(s)\n",
    "    cols += s\n",
    "    data += [1]*len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_full_sp = csr_matrix((np.array(data),\n",
    "                                (np.array(rows),\n",
    "                                 np.array(cols))),\n",
    "                               shape=(train_full.shape[0],len(ohe_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del rows\n",
    "del cols\n",
    "del data\n",
    "del train_full \n",
    "del ohe_dict\n",
    "del all_values\n",
    "del train_raw\n",
    "del people "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_full_sp, \n",
    "                                                    Y, \n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test logistic regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cvalues = [ 1.0, 1e2, 1e3, 1e4 ]\n",
    "results = []\n",
    "for c in cvalues:\n",
    "    lr = LogisticRegression(C=c, max_iter=500, tol=1e-5, n_jobs=CPUS)\n",
    "    lr.fit(X_train, y_train)\n",
    "    predictions = lr.predict_proba(X_test)\n",
    "    ll = log_loss(y_test, predictions)\n",
    "    a = accuracy_score(y_test, np.argmax(predictions,axis=1))\n",
    "    auc = roc_auc_score(np.c_[y_test==0, y_test==1], predictions)\n",
    "    r = {'c':c,'logloss':ll,'accuracy':a,'AUC':auc}\n",
    "    print '''C:{c} Log-Loss:{logloss:.7f} Accuracy:{accuracy:.7f} AUC:{AUC:.7f}\n",
    "    '''.format(**r)\n",
    "    results.append()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm = SVC(C=1.0, n_jobs=CPUS)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = svm.predict(X_test)\n",
    "ll = log_loss(y_test, predictions)\n",
    "a = accuracy_score(y_test, predictions)\n",
    "print 'Accuracy: {}%, Log-loss: {}'.format(round(a*100,2),round(ll,4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
